{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset\n",
        "\n",
        "Utilizaremos un corpues compuesto por obras de Jorge Luis Borges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-19 13:22:10.679170: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745079730.701679    5789 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745079730.708799    5789 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1745079730.726253    5789 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1745079730.726279    5789 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1745079730.726281    5789 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1745079730.726284    5789 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1745079736.165523    5789 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "# Para TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "import lxml\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "# descargar de textos.info\n",
        "import urllib.request\n",
        "\n",
        "# Para leer y parsear el texto en HTML de wikipedia\n",
        "import bs4 as bs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMjTSHg9-oXV",
        "outputId": "25e2091d-a62e-4ed6-a1a2-21ccb68e4356"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El dataset ya se encuentra descargado\n"
          ]
        }
      ],
      "source": [
        "# Descargar la carpeta de dataset\n",
        "import os\n",
        "import platform\n",
        "if os.access('full_corpus.csv', os.F_OK) is False:\n",
        "        if platform.system() == 'Windows':\n",
        "            !curl https://raw.githubusercontent.com/karen-pal/borges/refs/heads/master/datasets/full_corpus.csv -o full_corpus.csv\n",
        "        else:\n",
        "            !wget gull_corpus.csv https://raw.githubusercontent.com/karen-pal/borges/refs/heads/master/datasets/full_corpus.csv\n",
        "\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUKyXuq5-tbh",
        "outputId": "b3a65a51-d340-4249-9a57-16d707fa29f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de documentos: 30\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>metadata</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>https://ciudadseva.com/texto/abel-y-cain-borges/</td>\n",
              "      <td>Abel y Caín se encontraron después de la muert...</td>\n",
              "      <td>Abel y Caín</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>https://ciudadseva.com/texto/adrogue/</td>\n",
              "      <td>Era muy lindo, un pueblo laberíntico. A veces,...</td>\n",
              "      <td>Adrogué</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>https://ciudadseva.com/texto/alguien-sonara/</td>\n",
              "      <td>¿Qué soñará el indescifrable futuro? Soñará qu...</td>\n",
              "      <td>Alguien soñará</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>https://ciudadseva.com/texto/andres-armoa/</td>\n",
              "      <td>Los años le han dejado unas palabras en guaran...</td>\n",
              "      <td>Andrés Armoa</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>https://ciudadseva.com/texto/argumentum-ornith...</td>\n",
              "      <td>Cierro los ojos y veo una bandada de pájaros. ...</td>\n",
              "      <td>Argumentum ornithologicum</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>https://ciudadseva.com/texto/biografia-de-tade...</td>\n",
              "      <td>El seis de febrero de 1829, los montoneros que...</td>\n",
              "      <td>Biografía de Tadeo Isidoro Cruz</td>\n",
              "      <td>(1829-1874)</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>https://ciudadseva.com/texto/biografia-de-tade...</td>\n",
              "      <td>El seis de febrero de 1829, los montoneros que...</td>\n",
              "      <td>Biografía de Tadeo Isidoro Cruz</td>\n",
              "      <td>(1829-1874)</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>https://ciudadseva.com/texto/del-rigor-en-la-c...</td>\n",
              "      <td>En aquel Imperio, el Arte de la Cartografía lo...</td>\n",
              "      <td>Del Rigor en la Ciencia</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>https://ciudadseva.com/texto/dialogo-sobre-un-...</td>\n",
              "      <td>A- Distraídos en razonar la inmortalidad, habí...</td>\n",
              "      <td>Diálogo sobre un diálogo</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>https://ciudadseva.com/texto/el-acercamiento-a...</td>\n",
              "      <td>Philip Guedalla escribe que la novela The appr...</td>\n",
              "      <td>El acercamiento a Almotásim</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>https://ciudadseva.com/texto/el-adivino-2/</td>\n",
              "      <td>En Sumatra, alguien quiere doctorarse de adivi...</td>\n",
              "      <td>El adivino</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>https://ciudadseva.com/texto/el-aleph/</td>\n",
              "      <td>La candente mañana de febrero en que Beatriz V...</td>\n",
              "      <td>El Aleph</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>https://ciudadseva.com/texto/el-cautivo/</td>\n",
              "      <td>En Junín o en Tapalqué refieren la historia. U...</td>\n",
              "      <td>El cautivo</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>https://ciudadseva.com/texto/el-evangelio-segu...</td>\n",
              "      <td>El hecho sucedió en la estancia Los Álamos, en...</td>\n",
              "      <td>El evangelio según Marcos</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>https://ciudadseva.com/texto/el-fin-borges/</td>\n",
              "      <td>Recabarren, tendido, entreabrió los ojos y vio...</td>\n",
              "      <td>El fin</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>https://ciudadseva.com/texto/el-informe-de-bro...</td>\n",
              "      <td>En un ejemplar del primer volumen de las Mil y...</td>\n",
              "      <td>El informe de Brodie</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>https://ciudadseva.com/texto/el-inmortal-borges/</td>\n",
              "      <td>En Londres, a principios del mes de junio de 1...</td>\n",
              "      <td>El inmortal</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>https://ciudadseva.com/texto/el-jardin-de-los-...</td>\n",
              "      <td>En la página 242 de la Historia de la guerra e...</td>\n",
              "      <td>El jardín de los senderos que se bifurcan</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>https://ciudadseva.com/texto/el-libro-de-arena/</td>\n",
              "      <td>La línea consta de un número infinito de punto...</td>\n",
              "      <td>El libro de arena</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>https://ciudadseva.com/texto/el-milagro-secreto/</td>\n",
              "      <td>La noche del catorce de marzo de 1939, en un d...</td>\n",
              "      <td>El milagro secreto</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>https://ciudadseva.com/texto/el-muerto/</td>\n",
              "      <td>Que un hombre del suburbio de Buenos Aires, qu...</td>\n",
              "      <td>El muerto</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>https://ciudadseva.com/texto/el-palacio/</td>\n",
              "      <td>El Palacio no es infinito. Los muros, los terr...</td>\n",
              "      <td>El Palacio</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>https://ciudadseva.com/texto/el-perro-de-doble...</td>\n",
              "      <td>El perro que guardaba los rebaños del triforme...</td>\n",
              "      <td>El perro de doble cuerpo</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>https://ciudadseva.com/texto/el-punal/</td>\n",
              "      <td>En un cajón hay un puñal. Fue forjado en Toled...</td>\n",
              "      <td>El puñal</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>https://ciudadseva.com/texto/el-sur/</td>\n",
              "      <td>El hombre que desembarcó en Buenos Aires en 18...</td>\n",
              "      <td>El sur</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>https://ciudadseva.com/texto/emma-zunz/</td>\n",
              "      <td>El catorce de enero de 1922, Emma Zunz, al vol...</td>\n",
              "      <td>Emma Zunz</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>https://ciudadseva.com/texto/episodio-del-enem...</td>\n",
              "      <td>Tantos años huyendo y esperando y ahora el ene...</td>\n",
              "      <td>Episodio del enemigo</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>https://ciudadseva.com/texto/examen-de-la-obra...</td>\n",
              "      <td>Herbert Quain ha muerto en Roscommon; he compr...</td>\n",
              "      <td>Examen de la obra de Herbert Quain</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>https://ciudadseva.com/texto/funes-el-memorioso/</td>\n",
              "      <td>Lo recuerdo (yo no tengo derecho a pronunciar ...</td>\n",
              "      <td>Funes el memorioso</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>https://ciudadseva.com/texto/historia-de-rosen...</td>\n",
              "      <td>Serían las once de la noche, yo había entrado ...</td>\n",
              "      <td>Historia de Rosendo Juárez</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  link  \\\n",
              "144   https://ciudadseva.com/texto/abel-y-cain-borges/   \n",
              "145              https://ciudadseva.com/texto/adrogue/   \n",
              "146       https://ciudadseva.com/texto/alguien-sonara/   \n",
              "147         https://ciudadseva.com/texto/andres-armoa/   \n",
              "148  https://ciudadseva.com/texto/argumentum-ornith...   \n",
              "149  https://ciudadseva.com/texto/biografia-de-tade...   \n",
              "150  https://ciudadseva.com/texto/biografia-de-tade...   \n",
              "151  https://ciudadseva.com/texto/del-rigor-en-la-c...   \n",
              "152  https://ciudadseva.com/texto/dialogo-sobre-un-...   \n",
              "153  https://ciudadseva.com/texto/el-acercamiento-a...   \n",
              "154         https://ciudadseva.com/texto/el-adivino-2/   \n",
              "155             https://ciudadseva.com/texto/el-aleph/   \n",
              "156           https://ciudadseva.com/texto/el-cautivo/   \n",
              "157  https://ciudadseva.com/texto/el-evangelio-segu...   \n",
              "158        https://ciudadseva.com/texto/el-fin-borges/   \n",
              "159  https://ciudadseva.com/texto/el-informe-de-bro...   \n",
              "160   https://ciudadseva.com/texto/el-inmortal-borges/   \n",
              "161  https://ciudadseva.com/texto/el-jardin-de-los-...   \n",
              "162    https://ciudadseva.com/texto/el-libro-de-arena/   \n",
              "163   https://ciudadseva.com/texto/el-milagro-secreto/   \n",
              "164            https://ciudadseva.com/texto/el-muerto/   \n",
              "165           https://ciudadseva.com/texto/el-palacio/   \n",
              "166  https://ciudadseva.com/texto/el-perro-de-doble...   \n",
              "167             https://ciudadseva.com/texto/el-punal/   \n",
              "168               https://ciudadseva.com/texto/el-sur/   \n",
              "169            https://ciudadseva.com/texto/emma-zunz/   \n",
              "170  https://ciudadseva.com/texto/episodio-del-enem...   \n",
              "171  https://ciudadseva.com/texto/examen-de-la-obra...   \n",
              "172   https://ciudadseva.com/texto/funes-el-memorioso/   \n",
              "173  https://ciudadseva.com/texto/historia-de-rosen...   \n",
              "\n",
              "                                                  text  \\\n",
              "144  Abel y Caín se encontraron después de la muert...   \n",
              "145  Era muy lindo, un pueblo laberíntico. A veces,...   \n",
              "146  ¿Qué soñará el indescifrable futuro? Soñará qu...   \n",
              "147  Los años le han dejado unas palabras en guaran...   \n",
              "148  Cierro los ojos y veo una bandada de pájaros. ...   \n",
              "149  El seis de febrero de 1829, los montoneros que...   \n",
              "150  El seis de febrero de 1829, los montoneros que...   \n",
              "151  En aquel Imperio, el Arte de la Cartografía lo...   \n",
              "152  A- Distraídos en razonar la inmortalidad, habí...   \n",
              "153  Philip Guedalla escribe que la novela The appr...   \n",
              "154  En Sumatra, alguien quiere doctorarse de adivi...   \n",
              "155  La candente mañana de febrero en que Beatriz V...   \n",
              "156  En Junín o en Tapalqué refieren la historia. U...   \n",
              "157  El hecho sucedió en la estancia Los Álamos, en...   \n",
              "158  Recabarren, tendido, entreabrió los ojos y vio...   \n",
              "159  En un ejemplar del primer volumen de las Mil y...   \n",
              "160  En Londres, a principios del mes de junio de 1...   \n",
              "161  En la página 242 de la Historia de la guerra e...   \n",
              "162  La línea consta de un número infinito de punto...   \n",
              "163  La noche del catorce de marzo de 1939, en un d...   \n",
              "164  Que un hombre del suburbio de Buenos Aires, qu...   \n",
              "165  El Palacio no es infinito. Los muros, los terr...   \n",
              "166  El perro que guardaba los rebaños del triforme...   \n",
              "167  En un cajón hay un puñal. Fue forjado en Toled...   \n",
              "168  El hombre que desembarcó en Buenos Aires en 18...   \n",
              "169  El catorce de enero de 1922, Emma Zunz, al vol...   \n",
              "170  Tantos años huyendo y esperando y ahora el ene...   \n",
              "171  Herbert Quain ha muerto en Roscommon; he compr...   \n",
              "172  Lo recuerdo (yo no tengo derecho a pronunciar ...   \n",
              "173  Serían las once de la noche, yo había entrado ...   \n",
              "\n",
              "                                         title  \\\n",
              "144                                Abel y Caín   \n",
              "145                                    Adrogué   \n",
              "146                             Alguien soñará   \n",
              "147                               Andrés Armoa   \n",
              "148                  Argumentum ornithologicum   \n",
              "149            Biografía de Tadeo Isidoro Cruz   \n",
              "150            Biografía de Tadeo Isidoro Cruz   \n",
              "151                    Del Rigor en la Ciencia   \n",
              "152                   Diálogo sobre un diálogo   \n",
              "153                El acercamiento a Almotásim   \n",
              "154                                 El adivino   \n",
              "155                                   El Aleph   \n",
              "156                                 El cautivo   \n",
              "157                  El evangelio según Marcos   \n",
              "158                                     El fin   \n",
              "159                       El informe de Brodie   \n",
              "160                                El inmortal   \n",
              "161  El jardín de los senderos que se bifurcan   \n",
              "162                          El libro de arena   \n",
              "163                         El milagro secreto   \n",
              "164                                  El muerto   \n",
              "165                                 El Palacio   \n",
              "166                   El perro de doble cuerpo   \n",
              "167                                   El puñal   \n",
              "168                                     El sur   \n",
              "169                                  Emma Zunz   \n",
              "170                       Episodio del enemigo   \n",
              "171         Examen de la obra de Herbert Quain   \n",
              "172                         Funes el memorioso   \n",
              "173                 Historia de Rosendo Juárez   \n",
              "\n",
              "                           metadata             author  \n",
              "144  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "145  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "146  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "147  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "148  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "149                     (1829-1874)  Jorge Luis Borges  \n",
              "150                     (1829-1874)  Jorge Luis Borges  \n",
              "151  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "152  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "153      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "154  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "155      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "156  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "157      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "158      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "159      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "160      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "161      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "162      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "163      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "164      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "165  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "166  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "167  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "168      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "169      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "170  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "171      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "172      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "173      [Cuento - Texto completo.]  Jorge Luis Borges  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Nos quedamos unicamente 30 obras de Borges. Nota: se seleccionaron 30 unicamente por inconvenientes de RAM a la hora de entrenar los modelos\n",
        "\n",
        "df = pd.read_csv('full_corpus.csv').drop(columns=[\"Unnamed: 0\"])\n",
        "df_borges = df[df.author == 'Jorge Luis Borges'][:30]\n",
        "print(f'Cantidad de documentos: {df_borges.shape[0]}')\n",
        "df_borges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "neEB3s3h-1Ph"
      },
      "outputs": [],
      "source": [
        "# Concatenamos todas las obras de Borges y le eliminamos la palabra FIN, ya que la mayoría de las obras la tienen, con el fin de evitar relaciones impropias\n",
        "article_text = ' '.join(df_borges['text'].astype(str))\n",
        "article_text = article_text.replace('FIN', '')\n",
        "\n",
        "# Guardamos el corpus concatenado\n",
        "\n",
        "with open('obras_borges.csv', 'w', encoding='utf-8') as f:\n",
        "    f.write(article_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)\n",
        "\n",
        "# pasar todo el texto a minúscula\n",
        "article_text = article_text.lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwTK6xgLJd8q",
        "outputId": "db2b9e11-eee6-4df7-96b0-9498e0915eb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hZIlM52d_Z9g",
        "outputId": "40433db5-8c7f-45fc-9992-8ef8dfa4ba82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{' ',\n",
              " '!',\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '¡',\n",
              " '«',\n",
              " '²',\n",
              " '¹',\n",
              " '»',\n",
              " '¿',\n",
              " 'Á',\n",
              " 'É',\n",
              " 'Í',\n",
              " 'Ú',\n",
              " 'á',\n",
              " 'ä',\n",
              " 'é',\n",
              " 'ê',\n",
              " 'ë',\n",
              " 'í',\n",
              " 'ñ',\n",
              " 'ó',\n",
              " 'ö',\n",
              " 'ú',\n",
              " 'ü',\n",
              " '–',\n",
              " '—',\n",
              " '’',\n",
              " '“',\n",
              " '”',\n",
              " '…'}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chars_vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se observan algunas caracteres que pueden resultar irrelevantes para nuestro caso de estio como: '\\xad' ,'²', '³', '¹'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ijqD-bK__mcg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "68\n"
          ]
        }
      ],
      "source": [
        "# Eliminamos algunos caracteres que no son útiles y redefinimos chars_vocab\n",
        "article_text = article_text.replace('\\xad', '').replace('²', '').replace('³','').replace('¹', '')\n",
        "chars_vocab = set(article_text)\n",
        "print(len(chars_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "\n",
        "# Nota el diccionario char2idx se extrajo de una corrida previa y es necesario definirlo de manera hard-codeada para utilizar los modelos guardados\n",
        "char2idx = {'e': 0,\n",
        " '8': 1,\n",
        " '5': 2,\n",
        " 'c': 3,\n",
        " 't': 4,\n",
        " 'n': 5,\n",
        " '¿': 6,\n",
        " '¡': 7,\n",
        " 'l': 8,\n",
        " '—': 9,\n",
        " 'j': 10,\n",
        " ':': 11,\n",
        " 'f': 12,\n",
        " 'x': 13,\n",
        " 'z': 14,\n",
        " 'y': 15,\n",
        " 'u': 16,\n",
        " 'q': 17,\n",
        " '”': 18,\n",
        " '…': 19,\n",
        " 'á': 20,\n",
        " 'a': 21,\n",
        " 'g': 22,\n",
        " '-': 23,\n",
        " 'o': 24,\n",
        " ';': 25,\n",
        " '7': 26,\n",
        " '*': 27,\n",
        " '2': 28,\n",
        " 'w': 29,\n",
        " '!': 30,\n",
        " 'é': 31,\n",
        " 'í': 32,\n",
        " 'ú': 33,\n",
        " '(': 34,\n",
        " '4': 35,\n",
        " 'ü': 36,\n",
        " '?': 37,\n",
        " '6': 38,\n",
        " '’': 39,\n",
        " ' ': 40,\n",
        " 'ö': 41,\n",
        " 'm': 42,\n",
        " 'ê': 43,\n",
        " 'b': 44,\n",
        " 'i': 45,\n",
        " 'ñ': 46,\n",
        " 'v': 47,\n",
        " 'k': 48,\n",
        " 'r': 49,\n",
        " '.': 50,\n",
        " '1': 51,\n",
        " 'p': 52,\n",
        " ')': 53,\n",
        " '3': 54,\n",
        " '9': 55,\n",
        " '0': 56,\n",
        " '«': 57,\n",
        " '–': 58,\n",
        " '»': 59,\n",
        " 'ë': 60,\n",
        " 'h': 61,\n",
        " 's': 62,\n",
        " 'ó': 63,\n",
        " ',': 64,\n",
        " 'ä': 65,\n",
        " 'd': 66,\n",
        " '“': 67}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WSSmg9jtKP0T"
      },
      "outputs": [],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NmxQdxl8LRCg"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcKRl70HFTzG",
        "outputId": "a0a5a029-ef2e-4a90-aeab-5fa04c0bfe05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([21, 44,  0,  8, 40, 15, 40,  3, 21, 32,  5, 40, 62,  0, 40,  0,  5,\n",
              "        3, 24,  5,  4, 49, 21, 49, 24,  5, 40, 66,  0, 62, 52, 16, 31, 62,\n",
              "       40, 66,  0, 40,  8, 21, 40, 42, 16,  0, 49,  4,  0, 40, 66,  0, 40,\n",
              "       21, 44,  0,  8, 50, 40,  3, 21, 42, 45,  5, 21, 44, 21,  5, 40, 52,\n",
              "       24, 49, 40,  0,  8, 40, 66,  0, 62, 45,  0, 49,  4, 24, 40, 15, 40,\n",
              "       62,  0, 40, 49,  0,  3, 24,  5, 24,  3, 45,  0, 49, 24,  5])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVpLCKSZFXZO",
        "outputId": "cb42ca72-203e-418a-bb1a-722aad71dd9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([44,  0,  8, 40, 15, 40,  3, 21, 32,  5, 40, 62,  0, 40,  0,  5,  3,\n",
              "       24,  5,  4, 49, 21, 49, 24,  5, 40, 66,  0, 62, 52, 16, 31, 62, 40,\n",
              "       66,  0, 40,  8, 21, 40, 42, 16,  0, 49,  4,  0, 40, 66,  0, 40, 21,\n",
              "       44,  0,  8, 50, 40,  3, 21, 42, 45,  5, 21, 44, 21,  5, 40, 52, 24,\n",
              "       49, 40,  0,  8, 40, 66,  0, 62, 45,  0, 49,  4, 24, 40, 15, 40, 62,\n",
              "        0, 40, 49,  0,  3, 24,  5, 24,  3, 45,  0, 49, 24,  5, 40])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "# Definiendo los modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rkMCZvmhrQz4"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
        "\n",
        "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zUHX3r5JD-MG"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl,patience=5, name_model=\"my_model.keras\"):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.history_ppl = history_ppl\n",
        "      self.patience = patience\n",
        "      self.name_model = name_model\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        print(self.name_model)\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        self.history_ppl.append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          self.model.save(self.name_model)\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas `CategoryEncoding` que transforma a índices a vectores OHE y `TimeDistributed` que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "Zd2OkfQYs2Q7",
        "outputId": "84d4271c-4338-48b1-a155-968d92fa735e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nacho/.local/lib/python3.10/site-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,668</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │        \u001b[38;5;34m53,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)       │        \u001b[38;5;34m13,668\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,468</span> (263.55 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,468\u001b[0m (263.55 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,468</span> (263.55 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,468\u001b[0m (263.55 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Definimos para todos los modelos el vocab_size como la cantidad de caracteres permitidos\n",
        "\n",
        "vocab_size = len(chars_vocab)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oQq1PHDkxDvN",
        "outputId": "7cfdfc21-3837-4f93-ff7d-b3a65db928aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5425srnn.keras\n",
            "\n",
            " mean perplexity: 8.269874717443043 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 40ms/step - loss: 2.5423\n",
            "Epoch 2/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0750srnn.keras\n",
            "\n",
            " mean perplexity: 7.378323554992676 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - loss: 2.0749\n",
            "Epoch 3/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9580srnn.keras\n",
            "\n",
            " mean perplexity: 6.933388296884435 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - loss: 1.9579\n",
            "Epoch 4/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8954srnn.keras\n",
            "\n",
            " mean perplexity: 6.865189506352403 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.8954\n",
            "Epoch 5/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8576srnn.keras\n",
            "\n",
            " mean perplexity: 6.642576873757457 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 1.8576\n",
            "Epoch 6/20\n",
            "\u001b[1m924/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8324srnn.keras\n",
            "\n",
            " mean perplexity: 6.515368888396343 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - loss: 1.8324\n",
            "Epoch 7/20\n",
            "\u001b[1m922/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8143srnn.keras\n",
            "\n",
            " mean perplexity: 6.512457986824385 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 26ms/step - loss: 1.8143\n",
            "Epoch 8/20\n",
            "\u001b[1m924/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8007srnn.keras\n",
            "\n",
            " mean perplexity: 6.450381841368348 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 20ms/step - loss: 1.8007\n",
            "Epoch 9/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7882srnn.keras\n",
            "\n",
            " mean perplexity: 6.474379559964624 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.7882\n",
            "Epoch 10/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7803srnn.keras\n",
            "\n",
            " mean perplexity: 6.340836885776229 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.7803\n",
            "Epoch 11/20\n",
            "\u001b[1m924/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7730srnn.keras\n",
            "\n",
            " mean perplexity: 6.302483777508481 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 1.7730\n",
            "Epoch 12/20\n",
            "\u001b[1m923/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7649srnn.keras\n",
            "\n",
            " mean perplexity: 6.327579771744386 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - loss: 1.7649\n",
            "Epoch 13/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7599srnn.keras\n",
            "\n",
            " mean perplexity: 6.274072109287932 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.7599\n",
            "Epoch 14/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7556srnn.keras\n",
            "\n",
            " mean perplexity: 6.358556576357543 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 1.7556\n",
            "Epoch 15/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7500srnn.keras\n",
            "\n",
            " mean perplexity: 6.293218727330215 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.7500\n",
            "Epoch 16/20\n",
            "\u001b[1m924/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7474srnn.keras\n",
            "\n",
            " mean perplexity: 6.283082726802535 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.7474\n",
            "Epoch 17/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7426srnn.keras\n",
            "\n",
            " mean perplexity: 6.291513538542595 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.7426\n",
            "Epoch 18/20\n",
            "\u001b[1m922/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7396srnn.keras\n",
            "\n",
            " mean perplexity: 6.215693503845739 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - loss: 1.7396\n",
            "Epoch 19/20\n",
            "\u001b[1m924/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7367srnn.keras\n",
            "\n",
            " mean perplexity: 6.233448856204521 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 1.7367\n",
            "Epoch 20/20\n",
            "\u001b[1m923/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7346srnn.keras\n",
            "\n",
            " mean perplexity: 6.145303616541942 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.7346\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl,5, name_model=\"srnn.keras\")], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "K30JHB3Dv-mx",
        "outputId": "b9f9dc2e-e97e-4ec1-cad8-47c672eb490c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {
        "image.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resultados:\n",
        "- Épocas: 20\n",
        "- Perplexity final media: 6.14\n",
        "\n",
        "_Nota: el siguiente gráfico se obtuvo de un entrenamiento previo del modelo que no se muestra en los logs por falta de recursos de GPU de colab_\n",
        "\n",
        "\n",
        "Se observa una mejora en el modelo a medida que aumentan las épocas. En la época 5 se observa un cambio de desaceleración de mejora en la \"Perplexity\", y se alcanza un valor asíntotico de 6 en las épocas finales.\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Rhy5hZN38qfO"
      },
      "outputs": [],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model_srnn = keras.models.load_model('srnn.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GRU\n",
        "\n",
        "Este modelo se presenta como una evolución del modelo básico recurrente (SRNN) para el problema de \"Long Short Term Memory\", pero sin la misma perfomance que las redes LSTM, aunque sí, más sencillas y baratas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "collapsed": true,
        "id": "cDhdcSb5WxM2",
        "outputId": "36c4a95c-a871-44a2-e005-0bb02128d001"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">162,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,668</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │       \u001b[38;5;34m162,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)       │        \u001b[38;5;34m13,668\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,668</span> (686.20 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m175,668\u001b[0m (686.20 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,668</span> (686.20 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m175,668\u001b[0m (686.20 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from keras.layers import GRU\n",
        "\n",
        "model_gru = Sequential()\n",
        "\n",
        "model_gru.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model_gru.add(GRU(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model_gru.add(Dense(vocab_size, activation='softmax'))\n",
        "model_gru.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model_gru.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOtqXXHEYIuK",
        "outputId": "21bda966-efff-49ee-d461-3bfa1a9aa8e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 2.6177gru.keras\n",
            "\n",
            " mean perplexity: 8.599032279644304 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 354ms/step - loss: 2.6175\n",
            "Epoch 2/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 2.0566gru.keras\n",
            "\n",
            " mean perplexity: 7.501024678918242 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 354ms/step - loss: 2.0566\n",
            "Epoch 3/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.8958gru.keras\n",
            "\n",
            " mean perplexity: 6.87974998832659 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 352ms/step - loss: 1.8958\n",
            "Epoch 4/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.7816gru.keras\n",
            "\n",
            " mean perplexity: 6.499714834999492 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 335ms/step - loss: 1.7815\n",
            "Epoch 5/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.7027gru.keras\n",
            "\n",
            " mean perplexity: 6.37394799894959 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 334ms/step - loss: 1.7027\n",
            "Epoch 6/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.6465gru.keras\n",
            "\n",
            " mean perplexity: 6.198693280001633 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 333ms/step - loss: 1.6464\n",
            "Epoch 7/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 1.6044gru.keras\n",
            "\n",
            " mean perplexity: 6.117613453901451 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 335ms/step - loss: 1.6044\n",
            "Epoch 8/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.5720gru.keras\n",
            "\n",
            " mean perplexity: 6.183587798635468 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 333ms/step - loss: 1.5720\n",
            "Epoch 9/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.5459gru.keras\n",
            "\n",
            " mean perplexity: 6.066774421065818 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 349ms/step - loss: 1.5459\n",
            "Epoch 10/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 1.5246gru.keras\n",
            "\n",
            " mean perplexity: 6.0079903452451 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 350ms/step - loss: 1.5246\n",
            "Epoch 11/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 1.5059gru.keras\n",
            "\n",
            " mean perplexity: 6.019995794496463 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 342ms/step - loss: 1.5059\n",
            "Epoch 12/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 1.4918gru.keras\n",
            "\n",
            " mean perplexity: 5.975856031625326 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 332ms/step - loss: 1.4918\n",
            "Epoch 13/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 1.4784gru.keras\n",
            "\n",
            " mean perplexity: 6.01545962714057 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 330ms/step - loss: 1.4784\n",
            "Epoch 14/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.4672gru.keras\n",
            "\n",
            " mean perplexity: 5.9532086958412 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 330ms/step - loss: 1.4671\n",
            "Epoch 15/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 1.4571gru.keras\n",
            "\n",
            " mean perplexity: 5.956815078058316 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 331ms/step - loss: 1.4571\n",
            "Epoch 16/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.4479gru.keras\n",
            "\n",
            " mean perplexity: 5.938820927197696 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 349ms/step - loss: 1.4479\n",
            "Epoch 17/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 1.4399gru.keras\n",
            "\n",
            " mean perplexity: 6.013728716446243 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 331ms/step - loss: 1.4399\n",
            "Epoch 18/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.4335gru.keras\n",
            "\n",
            " mean perplexity: 5.949623551077515 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 350ms/step - loss: 1.4335\n",
            "Epoch 19/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.4266gru.keras\n",
            "\n",
            " mean perplexity: 6.000128871611967 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 335ms/step - loss: 1.4266\n",
            "Epoch 20/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.4207gru.keras\n",
            "\n",
            " mean perplexity: 5.995490247966679 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 333ms/step - loss: 1.4207\n"
          ]
        }
      ],
      "source": [
        "history_ppl = []\n",
        "hist = model_gru.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl,5, name_model=\"gru.keras\")], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "gzYsFfU1YTZP",
        "outputId": "2873d4af-f280-4b14-aca3-1f6a20cda60d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)"
      ]
    },
    {
      "attachments": {
        "image.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resultados:\n",
        "- Épocas: 20\n",
        "- Perplexity final media: 5.99\n",
        "\n",
        "_Nota: el siguiente gráfico se obtuvo de un entrenamiento previo del modelo que no se muestra en los logs por falta de recursos de GPU de colab_\n",
        "\n",
        "\n",
        "Al igual que en el SRNN, se observa una mejora en el modelo a medida que aumentan las épocas. En la época 5 se observa un cambio de desaceleración de mejora en la \"Perplexity\", y se alcanza un valor asíntotico de 6 en las épocas finales.\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model_gru = keras.models.load_model('gru.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LSTM (Long Short Term Memory)\n",
        "\n",
        "Este modelo presenta una solución forma al problema de \"gradiente evanescente\" propia de las RNN, en el cual se incorpora un estado de memoria de largo plazo y celdas que ponderan los términos más relevantes por medio de una entrada y salida propia de un catálogo de términos (C)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "-sIlkYWKXU_w",
        "outputId": "86807ab7-39cc-4f5e-b54f-61504983b16a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">220,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,874</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │       \u001b[38;5;34m220,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m)       │        \u001b[38;5;34m14,874\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,874</span> (917.48 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m234,874\u001b[0m (917.48 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,874</span> (917.48 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m234,874\u001b[0m (917.48 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from keras.layers import LSTM\n",
        "\n",
        "model_lstm = Sequential()\n",
        "\n",
        "model_lstm.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model_lstm.add(LSTM(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model_lstm.add(Dense(vocab_size, activation='softmax'))\n",
        "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model_lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hIVwR-qX-Uy",
        "outputId": "f800646d-e0f3-4eb4-9608-724c407b9dd5"
      },
      "outputs": [],
      "source": [
        "history_ppl = []\n",
        "hist = model_lstm.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl,5, name_model=\"lstm.keras\")], batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resultados:\n",
        "- Épocas: 20\n",
        "- Perplexity final media: 5.99\n",
        "\n",
        "_Nota: el siguiente gráfico se obtuvo de un entrenamiento previo del modelo que no se muestra en los logs por falta de recursos de GPU de colab_\n",
        "\n",
        "\n",
        "Al igual que en el SRNN, se observa una mejora en el modelo a medida que aumentan las épocas. En la época 5 se observa un cambio de desaceleración de mejora en la \"Perplexity\", y se alcanza un valor asíntotico de 6 en las épocas finales.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model_lstm = keras.models.load_model('lstm.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SRNN con optimizador \"Adam\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_size = len(chars_vocab)\n",
        "\n",
        "model_adam = Sequential()\n",
        "\n",
        "model_adam.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model_adam.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model_adam.add(Dense(vocab_size, activation='softmax'))\n",
        "model_adam.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model_adam.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history_ppl = []\n",
        "hist = model_adam.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl,5, name_model=\"srnn_adam.keras\")], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "# Predicción del próximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBvKHFPmzpy2",
        "outputId": "dfd6a06d-5baa-4180-dbee-51daa2aecae5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting typing_extensions==4.7.1\n",
            "  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: typing_extensions\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "typing-inspection 0.4.0 requires typing-extensions>=4.12.0, but you have typing-extensions 4.7.1 which is incompatible.\n",
            "pydantic 2.11.3 requires typing-extensions>=4.12.2, but you have typing-extensions 4.7.1 which is incompatible.\n",
            "fastapi 0.115.12 requires typing-extensions>=4.8.0, but you have typing-extensions 4.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing_extensions-4.7.1\n"
          ]
        }
      ],
      "source": [
        "# Se puede usar gradio para probar el modelo\n",
        "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
        "# https://gradio.app/\n",
        "\n",
        "!pip install -q gradio\n",
        "!pip install typing_extensions==4.7.1 --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "HNyBykvhzs7-",
        "outputId": "bf2a1df2-398a-41c6-8134-d6d2d1fcb08f"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "model = model_srnn # model_gru model_lstm\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "# Generación de secuencias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Greedy search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JoFqRC5pxzqS",
        "outputId": "74ba3b45-7445-4d2e-e9d5-2584dd85099c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Input text: \"bioy comtemplaba a un perro salir por la puerta de vidrio\"\n",
            "========================================\n",
            "Model: srnn.keras\n",
            "Output text: bioy comtemplaba a un perro salir por la puerta de vidrios en la casa de la casa de la casa de la\n",
            "========================================\n",
            "Model: lstm.keras\n",
            "Output text: bioy comtemplaba a un perro salir por la puerta de vidrio de la cara de la cara de la cara de la \n",
            "========================================\n",
            "Model: gru.keras\n",
            "Output text: bioy comtemplaba a un perro salir por la puerta de vidrio de la cara de la cara de la cara de la \n"
          ]
        }
      ],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "\n",
        "input_text='bioy comtemplaba a un perro salir por la puerta de vidrio'\n",
        "print('='*40)\n",
        "print(f'Input text: \\\"{input_text}\\\"')\n",
        "model_names = ['srnn.keras','lstm.keras','gru.keras']\n",
        "for model_name in model_names:\n",
        "    print('=' * 40)\n",
        "    print(f'Model: {model_name}')\n",
        "    model = keras.models.load_model(model_name)\n",
        "    output_text = generate_seq(model, input_text, max_length=max_context_size, n_words=40)\n",
        "    print(f'Output text: {output_text}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La generación de texto por medio del modelo \"Greedy Search\", encuentra el siguiente caracter más probable para la secuencia de entrada. Esto genera, junto con la falta muestreo aleatorio con temperatura, la generación de loops repetitivos, tal como pueden observarse en los ejemplos anteriores. \n",
        "\n",
        "A su vez, se observa como los modelos GRU y LSTM tienen un comporamiento similar, ya que en ambos casos se utilizan estrategías para reducir el problema del gradiente evanescente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "GeLqAoOYW1Hm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Input text: \"bioy comtemplaba\"\n",
            "========================================\n",
            "Model: srnn.keras\n",
            "Temp: 1\n",
            "Mode: det\n",
            "Output 1: bioy comtemplaba en un solo que el hombre de l\n",
            "Output 2: bioy comtemplaba en un solo que el hombre de u\n",
            "Output 3: bioy comtemplaba en un solo que el hombre. el \n",
            "Output 4: bioy comtemplaba en un solo que el hombre del \n",
            "Output 5: bioy comtemplaba en un solo que el hombre de a\n",
            "========================================\n",
            "Model: srnn.keras\n",
            "Temp: 1\n",
            "Mode: sto\n",
            "Output 1: bioy comtemplaba en la erena de un indificarar\n",
            "Output 2: bioy comtemplaba en la erena de un indificado \n",
            "Output 3: bioy comtemplaba en la erena de un indificara \n",
            "Output 4: bioy comtemplaba en la erena de un indificado,\n",
            "Output 5: bioy comtemplaba en la erena de un indificara \n",
            "========================================\n",
            "Model: srnn.keras\n",
            "Temp: 10\n",
            "Mode: det\n",
            "Output 1: bioy comtemplaba en un solo que el hombre de l\n",
            "Output 2: bioy comtemplaba en un solo que el hombre de u\n",
            "Output 3: bioy comtemplaba en un solo que el hombre. el \n",
            "Output 4: bioy comtemplaba en un solo que el hombre del \n",
            "Output 5: bioy comtemplaba en un solo que el hombre de a\n",
            "========================================\n",
            "Model: srnn.keras\n",
            "Temp: 10\n",
            "Mode: sto\n",
            "Output 1: bioy comtemplaba(hne,…hé—5o8de)äin(¡o…)uiuteóz\n",
            "Output 2: bioy comtemplaba(hne,…hé—5o8de)äin(¡o…)uiute c\n",
            "Output 3: bioy comtemplaba(hne,…hé—5o8de)äin(¡o…)uiute u\n",
            "Output 4: bioy comtemplaba(hne,…hé—5o8de)äin(¡o…)uiute é\n",
            "Output 5: bioy comtemplaba(hne,…hé—5o8de)äin(¡o…)uiuteó«\n",
            "========================================\n",
            "Model: srnn.keras\n",
            "Temp: 100\n",
            "Mode: det\n",
            "Output 1: bioy comtemplaba en un solo que el hombre de l\n",
            "Output 2: bioy comtemplaba en un solo que el hombre de u\n",
            "Output 3: bioy comtemplaba en un solo que el hombre. el \n",
            "Output 4: bioy comtemplaba en un solo que el hombre del \n",
            "Output 5: bioy comtemplaba en un solo que el hombre de a\n",
            "========================================\n",
            "Model: srnn.keras\n",
            "Temp: 100\n",
            "Mode: sto\n",
            "Output 1: bioy comtemplabaep’10jx4uc–’wh0h.x!¿h.;ly*«e0h\n",
            "Output 2: bioy comtemplabaep’10jx4uc–’wh0h.x!¿h“fijelñä…\n",
            "Output 3: bioy comtemplabaep’10jx4uc–’wh0h.x!¿h“fijelñäê\n",
            "Output 4: bioy comtemplabaep’10jx4uc–’wh0h.x!¿h.;ly*4-’7\n",
            "Output 5: bioy comtemplabaep’10jx4uc–’wh0h.x!¿h.;ly*«e0ü\n",
            "========================================\n",
            "Model: lstm.keras\n",
            "Temp: 1\n",
            "Mode: det\n",
            "Output 1: bioy comtemplaba en la casa de los hombres de \n",
            "Output 2: bioy comtemplaba en la casa de los hombres que\n",
            "Output 3: bioy comtemplaba en la casa de los hombres del\n",
            "Output 4: bioy comtemplaba en la casa de los hombres, la\n",
            "Output 5: bioy comtemplaba en la casa de los hombres, pe\n",
            "========================================\n",
            "Model: lstm.keras\n",
            "Temp: 1\n",
            "Mode: sto\n",
            "Output 1: bioy comtemplaba el hombre y con las tropas, e\n",
            "Output 2: bioy comtemplaba el hombre y con las tropas, f\n",
            "Output 3: bioy comtemplaba el hombre y con las tropas, “\n",
            "Output 4: bioy comtemplaba el hombre y con las tropas, m\n",
            "Output 5: bioy comtemplaba el hombre y con las tropas, p\n",
            "========================================\n",
            "Model: lstm.keras\n",
            "Temp: 10\n",
            "Mode: det\n",
            "Output 1: bioy comtemplaba en la casa de los hombres de \n",
            "Output 2: bioy comtemplaba en la casa de los hombres que\n",
            "Output 3: bioy comtemplaba en la casa de los hombres del\n",
            "Output 4: bioy comtemplaba en la casa de los hombres, la\n",
            "Output 5: bioy comtemplaba en la casa de los hombres, pe\n",
            "========================================\n",
            "Model: lstm.keras\n",
            "Temp: 10\n",
            "Mode: sto\n",
            "Output 1: bioy comtemplabasípímeouríásise?-)6íó 9zcnav¡u\n",
            "Output 2: bioy comtemplabasípímeouríásise?-)6íó 9äábdl,7\n",
            "Output 3: bioy comtemplabasípímeouríásise?-)6íó 9zcnav–n\n",
            "Output 4: bioy comtemplabasípímeouríásise?-)6íó 9äábdl–:\n",
            "Output 5: bioy comtemplabasípímeouríásise?-)6íó 9zcnav..\n",
            "========================================\n",
            "Model: lstm.keras\n",
            "Temp: 100\n",
            "Mode: det\n",
            "Output 1: bioy comtemplaba en la casa de los hombres de \n",
            "Output 2: bioy comtemplaba en la casa de los hombres que\n",
            "Output 3: bioy comtemplaba en la casa de los hombres del\n",
            "Output 4: bioy comtemplaba en la casa de los hombres, la\n",
            "Output 5: bioy comtemplaba en la casa de los hombres, pe\n",
            "========================================\n",
            "Model: lstm.keras\n",
            "Temp: 100\n",
            "Mode: sto\n",
            "Output 1: bioy comtemplabaó-a6x¡é”?e5j2»lo-,öy“*4*? 2od-\n",
            "Output 2: bioy comtemplabaó-a6x¡é”?e5j2»lo-,öy“*4*? 22.q\n",
            "Output 3: bioy comtemplabaó-a6x¡é”?e5j2»lo-,öy“*4*? 2…h¿\n",
            "Output 4: bioy comtemplabaó-a6x¡é”?e5j2»lo-,öy“*4*s1f¿”,\n",
            "Output 5: bioy comtemplabaó-a6x¡é”?e5j2»lo-,öy“*4*s1f¿ü?\n",
            "========================================\n",
            "Model: gru.keras\n",
            "Temp: 1\n",
            "Mode: det\n",
            "Output 1: bioy comtemplaba que los hombres de los hombre\n",
            "Output 2: bioy comtemplaba que los hombres de la primera\n",
            "Output 3: bioy comtemplaba que los hombres de la cara de\n",
            "Output 4: bioy comtemplaba que los hombres de la calle g\n",
            "Output 5: bioy comtemplaba que los hombres de la calle d\n",
            "========================================\n",
            "Model: gru.keras\n",
            "Temp: 1\n",
            "Mode: sto\n",
            "Output 1: bioy comtemplaba que el desconocido por la dic\n",
            "Output 2: bioy comtemplaba que el desconocido por la cam\n",
            "Output 3: bioy comtemplaba que el desconocido por la cas\n",
            "Output 4: bioy comtemplaba que el desconocido por la tie\n",
            "Output 5: bioy comtemplaba que el desconocido por la tid\n",
            "========================================\n",
            "Model: gru.keras\n",
            "Temp: 10\n",
            "Mode: det\n",
            "Output 1: bioy comtemplaba que los hombres de los hombre\n",
            "Output 2: bioy comtemplaba que los hombres de la primera\n",
            "Output 3: bioy comtemplaba que los hombres de la cara de\n",
            "Output 4: bioy comtemplaba que los hombres de la calle g\n",
            "Output 5: bioy comtemplaba que los hombres de la calle d\n",
            "========================================\n",
            "Model: gru.keras\n",
            "Temp: 10\n",
            "Mode: sto\n",
            "Output 1: bioy comtemplaba 49’”l)9: éy, sqg3 “-6öy”dwe,0\n",
            "Output 2: bioy comtemplaba 49’”l)9: éy, sqg3 “-6öy”d0v-m\n",
            "Output 3: bioy comtemplaba 49’”l)9: éy, sqg3 “-6öy”dwe-ú\n",
            "Output 4: bioy comtemplaba 49’”l)9: éy, sqg3 “-6öy”dwe-ä\n",
            "Output 5: bioy comtemplaba 49’”l)9: éy, sqg3 “-6öy”dwe-y\n",
            "========================================\n",
            "Model: gru.keras\n",
            "Temp: 100\n",
            "Mode: det\n",
            "Output 1: bioy comtemplaba que los hombres de los hombre\n",
            "Output 2: bioy comtemplaba que los hombres de la primera\n",
            "Output 3: bioy comtemplaba que los hombres de la cara de\n",
            "Output 4: bioy comtemplaba que los hombres de la calle g\n",
            "Output 5: bioy comtemplaba que los hombres de la calle d\n",
            "========================================\n",
            "Model: gru.keras\n",
            "Temp: 100\n",
            "Mode: sto\n",
            "Output 1: bioy comtemplaba–,6:)jnë*wi7bënr? a).ä1fgn;gó:\n",
            "Output 2: bioy comtemplaba–,6:)jnë*wi7bënr? a).jd)ä”h)ë \n",
            "Output 3: bioy comtemplaba–,6:)jnë*wi7bënr? a).jd)ä”:6d.\n",
            "Output 4: bioy comtemplaba–,6:)jnë*wi7bënr? a).jd)ä”h)z?\n",
            "Output 5: bioy comtemplaba–,6:)jnë*wi7bënr? a).jd)ä”h)ë2\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "input_text='bioy comtemplaba'\n",
        "print('='*40)\n",
        "print(f'Input text: \\\"{input_text}\\\"')\n",
        "model_names = ['srnn.keras','lstm.keras','gru.keras']\n",
        "temp_values = [1,10,100]\n",
        "modes = ['det','sto']\n",
        "for model_name in model_names:\n",
        "    for temp in temp_values:\n",
        "        for mode in modes:\n",
        "            print('=' * 40)\n",
        "            print(f'Model: {model_name}')\n",
        "            print(f'Temp: {temp}')\n",
        "            print(f'Mode: {mode}')\n",
        "            model = keras.models.load_model(model_name)\n",
        "            salidas = beam_search(model,num_beams=5,num_words=30,input=input_text,temp=temp,mode=mode)\n",
        "            # veamos las salidas mas probables\n",
        "            for idx,salida in enumerate(salidas):\n",
        "                print(f'Output {idx+1}: {decode(salida)}')\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusiones\n",
        "\n",
        "Al comparar los resultados de los distintos modelos utilizando el método de predicción con \"Beam Search\", podemos extraer las siguientes conclusiones:\n",
        "- Al comparar los modelos por separado, de manera deterministica, el modelo LSTM genera texto más coherente, gramatical y fluido. Lo que demuestra que la SRNN tiene menor capacidad para modelar dependencias largas que la LSTM\n",
        "- Al incluir la temperatura en la predicción de resultados,ambos modelos estan infiriendo caracteres extremadamente improbables, lo que demuestra la gran dependencia que existe con la temperatura. Esto indica que las distribuciones de probabilidad deterministicas no se encuentra muy desbalanceadas entre sí, haciendolos muy sensibles a cualquier \"ruido\" estocástico.\n",
        "- Si comparamos la complejidad de los modelos, la cantidad de parámetros entrenables, obseramos que la más sencilla es la SRNN con 70000 parametros aproximadamente, la GRU con 180000 parámetros aproximadamente (x2.6) y la LSTM con 225000 parámetros aproximadamente (x3.25), lo cual se relaciona con el resultado final, obteniendo frases más comprensibles con los últimos dos modelos en comparación con la primera. Sin embargo, los niveles de \"perplexity\" en todos los casos alcanzan valores similares, lo cual nos da a entender que analizar una red únicamente por medio de este parámetro es incompleto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_LlqmtEW1Hn"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
