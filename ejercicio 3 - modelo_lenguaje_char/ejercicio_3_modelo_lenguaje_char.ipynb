{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjlUw7dG-_5n"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "Utilizaremos un corpues compuesto por obras de Jorge Luis Borges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjCBkQdC-_5o",
        "outputId": "8974846a-c8ea-4eb4-9f45-766932f4cce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "import lxml\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "# descargar de textos.info\n",
        "import urllib.request\n",
        "\n",
        "# Para leer y parsear el texto en HTML de wikipedia\n",
        "import bs4 as bs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMjTSHg9-oXV",
        "outputId": "e244f54d-a02d-464a-cc5c-aa97d350b44d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-20 20:56:39--  http://gull_corpus.csv/\n",
            "Resolving gull_corpus.csv (gull_corpus.csv)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘gull_corpus.csv’\n",
            "--2025-04-20 20:56:39--  https://raw.githubusercontent.com/karen-pal/borges/refs/heads/master/datasets/full_corpus.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6022847 (5.7M) [text/plain]\n",
            "Saving to: ‘full_corpus.csv’\n",
            "\n",
            "full_corpus.csv     100%[===================>]   5.74M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-04-20 20:56:40 (344 MB/s) - ‘full_corpus.csv’ saved [6022847/6022847]\n",
            "\n",
            "FINISHED --2025-04-20 20:56:40--\n",
            "Total wall clock time: 1.0s\n",
            "Downloaded: 1 files, 5.7M in 0.02s (344 MB/s)\n"
          ]
        }
      ],
      "source": [
        "# Descargar la carpeta de dataset\n",
        "import os\n",
        "import platform\n",
        "if os.access('full_corpus.csv', os.F_OK) is False:\n",
        "        if platform.system() == 'Windows':\n",
        "            !curl https://raw.githubusercontent.com/karen-pal/borges/refs/heads/master/datasets/full_corpus.csv -o full_corpus.csv\n",
        "        else:\n",
        "            !wget gull_corpus.csv https://raw.githubusercontent.com/karen-pal/borges/refs/heads/master/datasets/full_corpus.csv\n",
        "\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bUKyXuq5-tbh",
        "outputId": "17228b32-82c9-4472-c532-f5ae1693c207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de documentos: 30\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  link  \\\n",
              "144   https://ciudadseva.com/texto/abel-y-cain-borges/   \n",
              "145              https://ciudadseva.com/texto/adrogue/   \n",
              "146       https://ciudadseva.com/texto/alguien-sonara/   \n",
              "147         https://ciudadseva.com/texto/andres-armoa/   \n",
              "148  https://ciudadseva.com/texto/argumentum-ornith...   \n",
              "149  https://ciudadseva.com/texto/biografia-de-tade...   \n",
              "150  https://ciudadseva.com/texto/biografia-de-tade...   \n",
              "151  https://ciudadseva.com/texto/del-rigor-en-la-c...   \n",
              "152  https://ciudadseva.com/texto/dialogo-sobre-un-...   \n",
              "153  https://ciudadseva.com/texto/el-acercamiento-a...   \n",
              "154         https://ciudadseva.com/texto/el-adivino-2/   \n",
              "155             https://ciudadseva.com/texto/el-aleph/   \n",
              "156           https://ciudadseva.com/texto/el-cautivo/   \n",
              "157  https://ciudadseva.com/texto/el-evangelio-segu...   \n",
              "158        https://ciudadseva.com/texto/el-fin-borges/   \n",
              "159  https://ciudadseva.com/texto/el-informe-de-bro...   \n",
              "160   https://ciudadseva.com/texto/el-inmortal-borges/   \n",
              "161  https://ciudadseva.com/texto/el-jardin-de-los-...   \n",
              "162    https://ciudadseva.com/texto/el-libro-de-arena/   \n",
              "163   https://ciudadseva.com/texto/el-milagro-secreto/   \n",
              "164            https://ciudadseva.com/texto/el-muerto/   \n",
              "165           https://ciudadseva.com/texto/el-palacio/   \n",
              "166  https://ciudadseva.com/texto/el-perro-de-doble...   \n",
              "167             https://ciudadseva.com/texto/el-punal/   \n",
              "168               https://ciudadseva.com/texto/el-sur/   \n",
              "169            https://ciudadseva.com/texto/emma-zunz/   \n",
              "170  https://ciudadseva.com/texto/episodio-del-enem...   \n",
              "171  https://ciudadseva.com/texto/examen-de-la-obra...   \n",
              "172   https://ciudadseva.com/texto/funes-el-memorioso/   \n",
              "173  https://ciudadseva.com/texto/historia-de-rosen...   \n",
              "\n",
              "                                                  text  \\\n",
              "144  Abel y Caín se encontraron después de la muert...   \n",
              "145  Era muy lindo, un pueblo laberíntico. A veces,...   \n",
              "146  ¿Qué soñará el indescifrable futuro? Soñará qu...   \n",
              "147  Los años le han dejado unas palabras en guaran...   \n",
              "148  Cierro los ojos y veo una bandada de pájaros. ...   \n",
              "149  El seis de febrero de 1829, los montoneros que...   \n",
              "150  El seis de febrero de 1829, los montoneros que...   \n",
              "151  En aquel Imperio, el Arte de la Cartografía lo...   \n",
              "152  A- Distraídos en razonar la inmortalidad, habí...   \n",
              "153  Philip Guedalla escribe que la novela The appr...   \n",
              "154  En Sumatra, alguien quiere doctorarse de adivi...   \n",
              "155  La candente mañana de febrero en que Beatriz V...   \n",
              "156  En Junín o en Tapalqué refieren la historia. U...   \n",
              "157  El hecho sucedió en la estancia Los Álamos, en...   \n",
              "158  Recabarren, tendido, entreabrió los ojos y vio...   \n",
              "159  En un ejemplar del primer volumen de las Mil y...   \n",
              "160  En Londres, a principios del mes de junio de 1...   \n",
              "161  En la página 242 de la Historia de la guerra e...   \n",
              "162  La línea consta de un número infinito de punto...   \n",
              "163  La noche del catorce de marzo de 1939, en un d...   \n",
              "164  Que un hombre del suburbio de Buenos Aires, qu...   \n",
              "165  El Palacio no es infinito. Los muros, los terr...   \n",
              "166  El perro que guardaba los rebaños del triforme...   \n",
              "167  En un cajón hay un puñal. Fue forjado en Toled...   \n",
              "168  El hombre que desembarcó en Buenos Aires en 18...   \n",
              "169  El catorce de enero de 1922, Emma Zunz, al vol...   \n",
              "170  Tantos años huyendo y esperando y ahora el ene...   \n",
              "171  Herbert Quain ha muerto en Roscommon; he compr...   \n",
              "172  Lo recuerdo (yo no tengo derecho a pronunciar ...   \n",
              "173  Serían las once de la noche, yo había entrado ...   \n",
              "\n",
              "                                         title  \\\n",
              "144                                Abel y Caín   \n",
              "145                                    Adrogué   \n",
              "146                             Alguien soñará   \n",
              "147                               Andrés Armoa   \n",
              "148                  Argumentum ornithologicum   \n",
              "149            Biografía de Tadeo Isidoro Cruz   \n",
              "150            Biografía de Tadeo Isidoro Cruz   \n",
              "151                    Del Rigor en la Ciencia   \n",
              "152                   Diálogo sobre un diálogo   \n",
              "153                El acercamiento a Almotásim   \n",
              "154                                 El adivino   \n",
              "155                                   El Aleph   \n",
              "156                                 El cautivo   \n",
              "157                  El evangelio según Marcos   \n",
              "158                                     El fin   \n",
              "159                       El informe de Brodie   \n",
              "160                                El inmortal   \n",
              "161  El jardín de los senderos que se bifurcan   \n",
              "162                          El libro de arena   \n",
              "163                         El milagro secreto   \n",
              "164                                  El muerto   \n",
              "165                                 El Palacio   \n",
              "166                   El perro de doble cuerpo   \n",
              "167                                   El puñal   \n",
              "168                                     El sur   \n",
              "169                                  Emma Zunz   \n",
              "170                       Episodio del enemigo   \n",
              "171         Examen de la obra de Herbert Quain   \n",
              "172                         Funes el memorioso   \n",
              "173                 Historia de Rosendo Juárez   \n",
              "\n",
              "                           metadata             author  \n",
              "144  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "145  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "146  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "147  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "148  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "149                     (1829-1874)  Jorge Luis Borges  \n",
              "150                     (1829-1874)  Jorge Luis Borges  \n",
              "151  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "152  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "153      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "154  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "155      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "156  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "157      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "158      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "159      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "160      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "161      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "162      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "163      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "164      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "165  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "166  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "167  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "168      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "169      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "170  [Minicuento - Texto completo.]  Jorge Luis Borges  \n",
              "171      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "172      [Cuento - Texto completo.]  Jorge Luis Borges  \n",
              "173      [Cuento - Texto completo.]  Jorge Luis Borges  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ad8485d-2508-4378-866f-8bdeea65578f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>metadata</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>https://ciudadseva.com/texto/abel-y-cain-borges/</td>\n",
              "      <td>Abel y Caín se encontraron después de la muert...</td>\n",
              "      <td>Abel y Caín</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>https://ciudadseva.com/texto/adrogue/</td>\n",
              "      <td>Era muy lindo, un pueblo laberíntico. A veces,...</td>\n",
              "      <td>Adrogué</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>https://ciudadseva.com/texto/alguien-sonara/</td>\n",
              "      <td>¿Qué soñará el indescifrable futuro? Soñará qu...</td>\n",
              "      <td>Alguien soñará</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>https://ciudadseva.com/texto/andres-armoa/</td>\n",
              "      <td>Los años le han dejado unas palabras en guaran...</td>\n",
              "      <td>Andrés Armoa</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>https://ciudadseva.com/texto/argumentum-ornith...</td>\n",
              "      <td>Cierro los ojos y veo una bandada de pájaros. ...</td>\n",
              "      <td>Argumentum ornithologicum</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>https://ciudadseva.com/texto/biografia-de-tade...</td>\n",
              "      <td>El seis de febrero de 1829, los montoneros que...</td>\n",
              "      <td>Biografía de Tadeo Isidoro Cruz</td>\n",
              "      <td>(1829-1874)</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>https://ciudadseva.com/texto/biografia-de-tade...</td>\n",
              "      <td>El seis de febrero de 1829, los montoneros que...</td>\n",
              "      <td>Biografía de Tadeo Isidoro Cruz</td>\n",
              "      <td>(1829-1874)</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>https://ciudadseva.com/texto/del-rigor-en-la-c...</td>\n",
              "      <td>En aquel Imperio, el Arte de la Cartografía lo...</td>\n",
              "      <td>Del Rigor en la Ciencia</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>https://ciudadseva.com/texto/dialogo-sobre-un-...</td>\n",
              "      <td>A- Distraídos en razonar la inmortalidad, habí...</td>\n",
              "      <td>Diálogo sobre un diálogo</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>https://ciudadseva.com/texto/el-acercamiento-a...</td>\n",
              "      <td>Philip Guedalla escribe que la novela The appr...</td>\n",
              "      <td>El acercamiento a Almotásim</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>https://ciudadseva.com/texto/el-adivino-2/</td>\n",
              "      <td>En Sumatra, alguien quiere doctorarse de adivi...</td>\n",
              "      <td>El adivino</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>https://ciudadseva.com/texto/el-aleph/</td>\n",
              "      <td>La candente mañana de febrero en que Beatriz V...</td>\n",
              "      <td>El Aleph</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>https://ciudadseva.com/texto/el-cautivo/</td>\n",
              "      <td>En Junín o en Tapalqué refieren la historia. U...</td>\n",
              "      <td>El cautivo</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>https://ciudadseva.com/texto/el-evangelio-segu...</td>\n",
              "      <td>El hecho sucedió en la estancia Los Álamos, en...</td>\n",
              "      <td>El evangelio según Marcos</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>https://ciudadseva.com/texto/el-fin-borges/</td>\n",
              "      <td>Recabarren, tendido, entreabrió los ojos y vio...</td>\n",
              "      <td>El fin</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>https://ciudadseva.com/texto/el-informe-de-bro...</td>\n",
              "      <td>En un ejemplar del primer volumen de las Mil y...</td>\n",
              "      <td>El informe de Brodie</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>https://ciudadseva.com/texto/el-inmortal-borges/</td>\n",
              "      <td>En Londres, a principios del mes de junio de 1...</td>\n",
              "      <td>El inmortal</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>https://ciudadseva.com/texto/el-jardin-de-los-...</td>\n",
              "      <td>En la página 242 de la Historia de la guerra e...</td>\n",
              "      <td>El jardín de los senderos que se bifurcan</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>https://ciudadseva.com/texto/el-libro-de-arena/</td>\n",
              "      <td>La línea consta de un número infinito de punto...</td>\n",
              "      <td>El libro de arena</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>https://ciudadseva.com/texto/el-milagro-secreto/</td>\n",
              "      <td>La noche del catorce de marzo de 1939, en un d...</td>\n",
              "      <td>El milagro secreto</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>https://ciudadseva.com/texto/el-muerto/</td>\n",
              "      <td>Que un hombre del suburbio de Buenos Aires, qu...</td>\n",
              "      <td>El muerto</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>https://ciudadseva.com/texto/el-palacio/</td>\n",
              "      <td>El Palacio no es infinito. Los muros, los terr...</td>\n",
              "      <td>El Palacio</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>https://ciudadseva.com/texto/el-perro-de-doble...</td>\n",
              "      <td>El perro que guardaba los rebaños del triforme...</td>\n",
              "      <td>El perro de doble cuerpo</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>https://ciudadseva.com/texto/el-punal/</td>\n",
              "      <td>En un cajón hay un puñal. Fue forjado en Toled...</td>\n",
              "      <td>El puñal</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>https://ciudadseva.com/texto/el-sur/</td>\n",
              "      <td>El hombre que desembarcó en Buenos Aires en 18...</td>\n",
              "      <td>El sur</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>https://ciudadseva.com/texto/emma-zunz/</td>\n",
              "      <td>El catorce de enero de 1922, Emma Zunz, al vol...</td>\n",
              "      <td>Emma Zunz</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>https://ciudadseva.com/texto/episodio-del-enem...</td>\n",
              "      <td>Tantos años huyendo y esperando y ahora el ene...</td>\n",
              "      <td>Episodio del enemigo</td>\n",
              "      <td>[Minicuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>https://ciudadseva.com/texto/examen-de-la-obra...</td>\n",
              "      <td>Herbert Quain ha muerto en Roscommon; he compr...</td>\n",
              "      <td>Examen de la obra de Herbert Quain</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>https://ciudadseva.com/texto/funes-el-memorioso/</td>\n",
              "      <td>Lo recuerdo (yo no tengo derecho a pronunciar ...</td>\n",
              "      <td>Funes el memorioso</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>https://ciudadseva.com/texto/historia-de-rosen...</td>\n",
              "      <td>Serían las once de la noche, yo había entrado ...</td>\n",
              "      <td>Historia de Rosendo Juárez</td>\n",
              "      <td>[Cuento - Texto completo.]</td>\n",
              "      <td>Jorge Luis Borges</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ad8485d-2508-4378-866f-8bdeea65578f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ad8485d-2508-4378-866f-8bdeea65578f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ad8485d-2508-4378-866f-8bdeea65578f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-27a76ac4-cb33-432c-b1b4-490fae165008\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-27a76ac4-cb33-432c-b1b4-490fae165008')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-27a76ac4-cb33-432c-b1b4-490fae165008 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f1b4868d-d123-4dc3-b358-72c91df0045a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_borges')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f1b4868d-d123-4dc3-b358-72c91df0045a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_borges');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_borges",
              "summary": "{\n  \"name\": \"df_borges\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"https://ciudadseva.com/texto/funes-el-memorioso/\",\n          \"https://ciudadseva.com/texto/el-jardin-de-los-senderos-que-se-bifurcan/\",\n          \"https://ciudadseva.com/texto/el-evangelio-segun-marcos/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"Lo recuerdo (yo no tengo derecho a pronunciar ese verbo sagrado, solo un hombre en la tierra tuvo derecho y ese hombre ha muerto) con una oscura pasionaria en la mano, vi\\u00e9ndola como nadie la ha visto, aunque la mirara desde el crep\\u00fasculo del d\\u00eda hasta el de la noche, toda una vida entera. Lo recuerdo, la cara taciturna y aindiada y singularmente remota, detr\\u00e1s del cigarrillo. Recuerdo (creo) sus manos afiladas de trenzador. Recuerdo cerca de esas manos un mate, con las armas de la Banda Oriental; recuerdo en la ventana de la casa una estera amarilla, con un vago paisaje lacustre. Recuerdo claramente su voz; la voz pausada, resentida y nasal del orillero antiguo, sin los silbidos italianos de ahora. M\\u00e1s de tres veces no lo vi; la \\u00faltima, en 1887\\u2026 Me parece muy feliz el proyecto de que todos aquellos que lo trataron escriban sobre \\u00e9l; mi testimonio ser\\u00e1 acaso el m\\u00e1s breve y sin duda el m\\u00e1s pobre, pero no el menos imparcial del volumen que editar\\u00e1n ustedes. Mi deplorable condici\\u00f3n de argentino me impedir\\u00e1 incurrir en el ditirambo \\u2014g\\u00e9nero obligatorio en el Uruguay, cuando el tema es un uruguayo. Literato, cajetilla, porte\\u00f1o: Funes no dijo esas injuriosas palabras, pero de un modo suficiente me consta que yo representaba para \\u00e9l esas desventuras. Pedro Leandro Ipuche ha escrito que Funes era un precursor de los superhombres; \\u201cUn Zarathustra cimarr\\u00f3n y vern\\u00e1culo\\u201d; no lo discuto, pero no hay que olvidar que era tambi\\u00e9n un compadrito de Fray Bentos, con ciertas incurables limitaciones. Mi primer recuerdo de Funes es muy perspicuo. Lo veo en un atardecer de marzo o febrero del a\\u00f1o ochenta y cuatro. Mi padre, ese a\\u00f1o, me hab\\u00eda llevado a veranear a Fray Bentos. Yo volv\\u00eda con mi primo Bernardo Haedo de la estancia de San Francisco. Volv\\u00edamos cantando, a caballo, y esa no era la \\u00fanica circunstancia de mi felicidad. Despu\\u00e9s de un d\\u00eda bochornoso, una enorme tormenta color pizarra hab\\u00eda escondido el cielo. La alentaba el viento del Sur, ya se enloquec\\u00edan los \\u00e1rboles; yo ten\\u00eda el temor (la esperanza) de que nos sorprendiera en un descampado el agua elemental. Corrimos una especie de carrera con la tormenta. Entramos en un callej\\u00f3n que se ahondaba entre dos veredas alt\\u00edsimas de ladrillo. Hab\\u00eda oscurecido de golpe; o\\u00ed r\\u00e1pidos y casi secretos pasos en lo alto; alc\\u00e9 los ojos y vi un muchacho que corr\\u00eda por la estrecha y rota vereda como por una estrecha y rota pared. Recuerdo la bombacha, las alpargatas, recuerdo el cigarrillo en el duro rostro, contra el nubarr\\u00f3n ya sin l\\u00edmites. Bernardo le grit\\u00f3 imprevisiblemente: \\u00bfQu\\u00e9 horas son, Ireneo? Sin consultar el cielo, sin detenerse, el otro respondi\\u00f3: Faltan cuatro minutos para las ocho, joven Bernardo Juan Francisco. La voz era aguda, burlona. Yo soy tan distra\\u00eddo que el di\\u00e1logo que acabo de referir no me hubiera llamado la atenci\\u00f3n si no lo hubiera recalcado mi primo, a quien estimulaban (creo) cierto orgullo local, y el deseo de mostrarse indiferente a la r\\u00e9plica tripartita del otro. Me dijo que el muchacho del callej\\u00f3n era un tal Ireneo Funes, mentado por algunas rarezas como la de no darse con nadie y la de saber siempre la hora, como un reloj. Agreg\\u00f3 que era hijo de una planchadora del pueblo, Mar\\u00eda Clementina Funes, y que algunos dec\\u00edan que su padre era un m\\u00e9dico del saladero, un ingl\\u00e9s O\\u2019Connor, y otros un domador o rastreador del departamento del Salto. Viv\\u00eda con su madre, a la vuelta de la quinta de los Laureles. Los a\\u00f1os ochenta y cinco y ochenta y seis veraneamos en la ciudad de Montevideo. El ochenta y siete volv\\u00ed a Fray Bentos. Pregunt\\u00e9, como es natural, por todos los conocidos y, finalmente, por el \\u201ccronom\\u00e9trico Funes\\u201d. Me contestaron que lo hab\\u00eda volteado un redom\\u00f3n en la estancia de San Francisco, y que hab\\u00eda quedado tullido, sin esperanza. Recuerdo la impresi\\u00f3n de inc\\u00f3moda magia que la noticia me produjo: la \\u00fanica vez que yo lo vi, ven\\u00edamos a caballo de San Francisco y \\u00e9l andaba en un lugar alto; el hecho, en boca de mi primo Bernardo, ten\\u00eda mucho de sue\\u00f1o elaborado con elementos anteriores. Me dijeron que no se mov\\u00eda del catre, puestos los ojos en la higuera del fondo o en una telara\\u00f1a. En los atardeceres, permit\\u00eda que lo sacaran a la ventana. Llevaba la soberbia hasta el punto de simular que era ben\\u00e9fico el golpe que lo hab\\u00eda fulminado\\u2026 Dos veces lo vi atr\\u00e1s de la reja, que burdamente recalcaba su condici\\u00f3n de eterno prisionero: una, inm\\u00f3vil, con los ojos cerrados; otra, inm\\u00f3vil tambi\\u00e9n, absorto en la contemplaci\\u00f3n de un oloroso gajo de santonina. No sin alguna vanagloria yo hab\\u00eda iniciado en aquel tiempo el estudio met\\u00f3dico del lat\\u00edn. Mi valija inclu\\u00eda el De viris illustribus de Lhomond, el Thesaurus de Quicherat, los comentarios de Julio C\\u00e9sar y un volumen impar de la Naturalis historia de Plinio, que exced\\u00eda (y sigue excediendo) mis m\\u00f3dicas virtudes de latinista. Todo se propala en un pueblo chico; Ireneo, en su rancho de las orillas, no tard\\u00f3 en enterarse del arribo de esos libros an\\u00f3malos. Me dirigi\\u00f3 una carta florida y ceremoniosa, en la que recordaba nuestro encuentro, desdichadamente fugaz, \\u201cdel d\\u00eda siete de febrero del a\\u00f1o ochenta y cuatro\\u201d, ponderaba los gloriosos servicios que don Gregorio Haedo, mi t\\u00edo, finado ese mismo a\\u00f1o, \\u201chab\\u00eda prestado a las dos patrias en la valerosa jornada de Ituzaing\\u00f3\\u201d, y me solicitaba el pr\\u00e9stamo de cualquiera de los vol\\u00famenes, acompa\\u00f1ado de un diccionario \\u201cpara la buena inteligencia del texto original, porque todav\\u00eda ignoro el lat\\u00edn\\u201d. Promet\\u00eda devolverlos en buen estado, casi inmediatamente. La letra era perfecta, muy perfilada; la ortograf\\u00eda, del tipo que Andr\\u00e9s Bello preconiz\\u00f3: i por y, j por g. Al principio, tem\\u00ed naturalmente una broma. Mis primos me aseguraron que no, que eran cosas de Ireneo. No supe si atribuir a descaro, a ignorancia o a estupidez la idea de que el arduo lat\\u00edn no requer\\u00eda m\\u00e1s instrumento que un diccionario; para desenga\\u00f1arlo con plenitud le mand\\u00e9 el Gradus ad Parnassum de Quicherat. y la obra de Plinio. El catorce de febrero me telegrafiaron de Buenos Aires que volviera inmediatamente, porque mi padre no estaba \\u201cnada bien\\u201d. Dios me perdone; el prestigio de ser el destinatario de un telegrama urgente, el deseo de comunicar a todo Fray Bentos la contradicci\\u00f3n entre la forma negativa de la noticia y el perentorio adverbio, la tentaci\\u00f3n de dramatizar mi dolor, fingiendo un viril estoicismo, tal vez me distrajeron de toda posibilidad de dolor. Al hacer la valija, not\\u00e9 que me faltaban el Gradus y el primer tomo de la Naturalis historia. El \\u201cSaturno\\u201d zarpaba al d\\u00eda siguiente, por la ma\\u00f1ana; esa noche, despu\\u00e9s de cenar, me encamin\\u00e9 a casa de Funes. Me asombr\\u00f3 que la noche fuera no menos pesada que el d\\u00eda. En el decente rancho, la madre de Funes me recibi\\u00f3. Me dijo que Ireneo estaba en la pieza del fondo y que no me extra\\u00f1ara encontrarla a oscuras, porque Ireneo sab\\u00eda pasarse las horas muertas sin encender la vela. Atraves\\u00e9 el patio de baldosa, el corredorcito; llegu\\u00e9 al segundo patio. Hab\\u00eda una parra; la oscuridad pudo parecerme total. O\\u00ed de pronto la alta y burlona voz de Ireneo. Esa voz hablaba en lat\\u00edn; esa voz (que ven\\u00eda de la tiniebla) articulaba con moroso deleite un discurso o plegaria o incantaci\\u00f3n. Resonaron las s\\u00edlabas romanas en el patio de tierra; mi temor las cre\\u00eda indescifrables, interminables; despu\\u00e9s, en el enorme di\\u00e1logo de esa noche, supe que formaban el primer p\\u00e1rrafo del vig\\u00e9simocuarto cap\\u00edtulo del libro s\\u00e9ptimo de la Naturalis historia. La materia de ese cap\\u00edtulo es la memoria; las palabras \\u00faltimas fueron ut nihil non usdem verbis redderetur auditum. Sin el menor cambio de voz, Ireneo me dijo que pasara. Estaba en el catre, fumando. Me parece que no le vi la cara hasta el alba; creo rememorar el ascua moment\\u00e1nea del cigarrillo. La pieza ol\\u00eda vagamente a humedad. Me sent\\u00e9; repet\\u00ed la historia del telegrama y de la enfermedad de mi padre. Arribo, ahora, al m\\u00e1s dif\\u00edcil punto de mi relato. Este (bueno es que ya lo sepa el lector) no tiene otro argumento que ese di\\u00e1logo de hace ya medio siglo. No tratar\\u00e9 de reproducir sus palabras, irrecuperables ahora. Prefiero resumir con veracidad las muchas cosas que me dijo Ireneo. El estilo indirecto es remoto y d\\u00e9bil; yo s\\u00e9 que sacrifico la eficacia de mi relato; que mis lectores se imaginen los entrecortados per\\u00edodos que me abrumaron esa noche. Ireneo empez\\u00f3 por enumerar, en lat\\u00edn y espa\\u00f1ol, los casos de memoria prodigiosa registrados por la Naturalis historia: Ciro, rey de los persas, que sab\\u00eda llamar por su nombre a todos los soldados de sus ej\\u00e9rcitos; Mitr\\u00eddates Eupator, que administraba la justicia en los 22 idiomas de su imperio; Sim\\u00f3nides, inventor de la mnemotecnia; Metrodoro, que profesaba el arte de repetir con fidelidad lo escuchado una sola vez. Con evidente buena fe se maravill\\u00f3 de que tales casos maravillaran. Me dijo que antes de esa tarde lluviosa en que lo volte\\u00f3 el azulejo, \\u00e9l hab\\u00eda sido lo que son todos los cristianos: un ciego, un sordo, un abombado, un desmemoriado. (Trat\\u00e9 de recordarle su percepci\\u00f3n exacta del tiempo, su memoria de nombres propios; no me hizo caso.) Diecinueve a\\u00f1os hab\\u00eda vivido como quien sue\\u00f1a: miraba sin ver, o\\u00eda sin o\\u00edr, se olvidaba de todo, de casi todo. Al caer, perdi\\u00f3 el conocimiento; cuando lo recobr\\u00f3, el presente era casi intolerable de tan rico y tan n\\u00edtido, y tambi\\u00e9n las memorias m\\u00e1s antiguas y m\\u00e1s triviales. Poco despu\\u00e9s averigu\\u00f3 que estaba tullido. El hecho apenas le interes\\u00f3. Razon\\u00f3 (sinti\\u00f3) que la inmovilidad era un precio m\\u00ednimo. Ahora su percepci\\u00f3n y su memoria eran infalibles. Nosotros, de un vistazo, percibimos tres copas en una mesa; Funes, todos los v\\u00e1stagos y racimos y frutos que comprende una parra. Sab\\u00eda las formas de las nubes australes del amanecer del treinta de abril de mil ochocientos ochenta y dos y pod\\u00eda compararlas en el recuerdo con las vetas de un libro en pasta espa\\u00f1ola que solo hab\\u00eda mirado una vez y con las l\\u00edneas de la espuma que un remo levant\\u00f3 en el R\\u00edo Negro la v\\u00edspera de la acci\\u00f3n del Quebracho. Esos recuerdos no eran simples; cada imagen visual estaba ligada a sensaciones musculares, t\\u00e9rmicas, etc. Pod\\u00eda reconstruir todos los sue\\u00f1os, todos los entresue\\u00f1os. Dos o tres veces hab\\u00eda reconstruido un d\\u00eda entero; no hab\\u00eda dudado nunca, pero cada reconstrucci\\u00f3n hab\\u00eda requerido un d\\u00eda entero. Me dijo: M\\u00e1s recuerdos tengo yo solo que los que habr\\u00e1n tenido todos los hombres desde que el mundo es mundo. Y tambi\\u00e9n: Mis sue\\u00f1os son como 1a vigilia de ustedes. Y tambi\\u00e9n, hacia el alba: Mi memor\\u00eda, se\\u00f1or, es como vac\\u00edadero de basuras. Una circunferencia en un pizarr\\u00f3n, un tri\\u00e1ngulo rect\\u00e1ngulo, un rombo, son formas que podemos intuir plenamente; lo mismo le pasaba a Ireneo con las aborrascadas crines de un potro, con una punta de ganado en una cuchilla, con el fuego cambiante y con la innumerable ceniza, con las muchas caras de un muerto en un largo velorio. No s\\u00e9 cu\\u00e1ntas estrellas ve\\u00eda en el cielo. Esas cosas me dijo; ni entonces ni despu\\u00e9s las he puesto en duda. En aquel tiempo no hab\\u00eda cinemat\\u00f3grafos ni fon\\u00f3grafos; es, sin embargo, inveros\\u00edmil y hasta incre\\u00edble que nadie hiciera un experimento con Funes. Lo cierto es que vivimos postergando todo lo postergable; tal vez todos sabemos profundamente que somos inmortales y que tarde o temprano, todo hombre har\\u00e1 todas las cosas y sabr\\u00e1 todo. La voz de Funes, desde la oscuridad, segu\\u00eda hablando. Me dijo que hacia 1886 hab\\u00eda discurrido un sistema original de numeraci\\u00f3n y que en muy pocos d\\u00edas hab\\u00eda rebasado el veinticuatro mil. No lo hab\\u00eda escrito, porque lo pensado una sola vez ya no pod\\u00eda borr\\u00e1rsele. Su primer est\\u00edmulo, creo, fue el desagrado de que los treinta y tres orientales requirieran dos signos y tres palabras, en lugar de una sola palabra y un solo signo. Aplic\\u00f3 luego ese disparatado principio a los otros n\\u00fameros. En lugar de siete mil trece, dec\\u00eda (por ejemplo) M\\u00e1ximo P\\u00e9rez; en lugar de siete mil catorce, El Ferrocarril; otros n\\u00fameros eran Luis Meli\\u00e1n Lafinur, Olimar, azufre, los bastos, la ballena, gas, la caldera, Napole\\u00f3n, Agust\\u00edn Vedia. En lugar de quinientos, dec\\u00eda nueve. Cada palabra ten\\u00eda un signo particular, una especie marca; las \\u00faltimas muy complicadas\\u2026 Yo trat\\u00e9 de explicarle que esa rapsodia de voces inconexas era precisamente lo contrario de un sistema numeraci\\u00f3n. Le dije que decir 365 era decir tres centenas, seis decenas, cinco unidades; an\\u00e1lisis no existe en los \\u201cn\\u00fameros\\u201d El Negro Timoteo o manta de carne. Funes no me entendi\\u00f3 o no quiso entenderme. Locke, en el siglo XVII, postul\\u00f3 (y reprob\\u00f3) un idioma imposible en el que cada cosa individual, cada piedra, cada p\\u00e1jaro y cada rama tuviera nombre propio; Funes proyect\\u00f3 alguna vez un idioma an\\u00e1logo, pero lo desech\\u00f3 por parecerle demasiado general, demasiado ambiguo. En efecto, Funes no solo recordaba cada hoja de cada \\u00e1rbol de cada monte, sino cada una de las veces que la hab\\u00eda percibido o imaginado. Resolvi\\u00f3 reducir cada una de sus jornadas pret\\u00e9ritas a unos setenta mil recuerdos, que definir\\u00eda luego por cifras. Lo disuadieron dos consideraciones: la conciencia de que la tarea era interminable, la conciencia de que era in\\u00fatil. Pens\\u00f3 que en la hora de la muerte no habr\\u00eda acabado a\\u00fan de clasificar todos los recuerdos de la ni\\u00f1ez. Los dos proyectos que he indicado (un vocabulario infinito para serie natural de los n\\u00fameros, un in\\u00fatil cat\\u00e1logo mental de todas las im\\u00e1genes del recuerdo) son insensatos, pero revelan cierta balbuciente grandeza. Nos dejan vislumbrar o inferir el vertiginoso mundo de Funes. Este, no lo olvidemos, era casi incapaz de ideas generales, plat\\u00f3nicas. No solo le costaba comprender que el s\\u00edmbolo gen\\u00e9rico perro abarcara tantos individuos dispares de diversos tama\\u00f1os y diversa forma; le molestaba que el perro de las tres y catorce (visto de perfil) tuviera el mismo nombre que el perro de las tres y cuarto (visto de frente). Su propia cara en el espejo, sus propias manos, lo sorprend\\u00edan cada vez. Refiere Swift que el emperador de Lilliput discern\\u00eda el movimiento del minutero; Funes discern\\u00eda continuamente los tranquilos avances de la corrupci\\u00f3n, de las caries, de la fatiga. Notaba los progresos de la muerte, de la humedad. Era el solitario y l\\u00facido espectador de un mundo multiforme, instant\\u00e1neo y casi intolerablemente preciso. Babilonia, Londres y Nueva York han abrumado con feroz esplendor la imaginaci\\u00f3n de los hombres; nadie, en sus torres populosas o en sus avenidas urgentes, ha sentido el calor y la presi\\u00f3n de una realidad tan infatigable como la que d\\u00eda y noche converg\\u00eda sobre el infeliz Ireneo, en su pobre arrabal sudamericano. Le era muy dif\\u00edcil dormir. Dormir es distraerse del mundo; Funes, de espaldas en el catre, en la sombra, se figuraba cada grieta y cada moldura de las casas precisas que lo rodeaban. (Repito que el menos importante de sus recuerdos era m\\u00e1s minucioso y m\\u00e1s vivo que nuestra percepci\\u00f3n de un goce f\\u00edsico o de un tormento f\\u00edsico.) Hacia el Este, en un trecho no amanzanado, hab\\u00eda casas nuevas, desconocidas. Funes las imaginaba negras, compactas, hechas de tiniebla homog\\u00e9nea; en esa direcci\\u00f3n volv\\u00eda la cara para dormir. Tambi\\u00e9n sol\\u00eda imaginarse en el fondo del r\\u00edo, mecido y anulado por la corriente. Hab\\u00eda aprendido sin esfuerzo el ingl\\u00e9s, el franc\\u00e9s, el portugu\\u00e9s, el lat\\u00edn. Sospecho, sin embargo, que no era muy capaz de pensar. Pensar es olvidar diferencias, es generalizar, abstraer. En el abarrotado mundo de Funes no hab\\u00eda sino detalles, casi inmediatos. La recelosa claridad de la madrugada entr\\u00f3 por el patio de tierra. Entonces vi la cara de la voz que toda la noche hab\\u00eda hablado. Ireneo ten\\u00eda diecinueve a\\u00f1os; hab\\u00eda nacido en 1868; me pareci\\u00f3 monumental como el bronce, m\\u00e1s antiguo que Egipto, anterior a las profec\\u00edas y a las pir\\u00e1mides. Pens\\u00e9 que cada una de mis palabras (que cada uno de mis gestos) perdurar\\u00eda en su implacable memoria; me entorpeci\\u00f3 el temor de multiplicar ademanes in\\u00fatiles. Ireneo Funes muri\\u00f3 en 1889, de una congesti\\u00f3n pulmonar. FIN Ficciones, 1944\",\n          \"En la p\\u00e1gina 242 de la Historia de la guerra europea, de Liddell Hart, se lee que una ofensiva de trece divisiones brit\\u00e1nicas (apoyadas por mil cuatrocientas piezas de artiller\\u00eda) contra la l\\u00ednea Serre-Montauban hab\\u00eda sido planeada para el veinticuatro de julio de 1916 y debi\\u00f3 postergarse hasta la ma\\u00f1ana del d\\u00eda veintinueve. Las lluvias torrenciales (anota el capit\\u00e1n Liddell Hart) provocaron esa demora -nada significativa, por cierto-. La siguiente declaraci\\u00f3n, dictada, rele\\u00edda y firmada por el doctor Yu Tsun, antiguo catedr\\u00e1tico de ingl\\u00e9s en la Hochschule de Tsingtao, arroja una insospechada luz sobre el caso. Faltan las dos p\\u00e1ginas iniciales. \\u201c\\u2026y colgu\\u00e9 el tubo. Inmediatamente despu\\u00e9s, reconoc\\u00ed la voz que hab\\u00eda contestado en alem\\u00e1n. Era la del capit\\u00e1n Richard Madden. Madden, en el departamento de Viktor Runeberg, quer\\u00eda decir el fin de nuestros afanes y -pero eso parec\\u00eda muy secundario, o deb\\u00eda parec\\u00e9rmelo\\u2013 tambi\\u00e9n de nuestras vidas. Quer\\u00eda decir que Runeberg hab\\u00eda sido arrestado, o asesinado\\u00b9. Antes que declinara el sol de ese d\\u00eda, yo correr\\u00eda la misma suerte. Madden era implacable. Mejor dicho, estaba obligado a ser implacable. Irland\\u00e9s a las \\u00f3rdenes de Inglaterra, hombre acusado de tibieza y tal vez de traici\\u00f3n, \\u00bfc\\u00f3mo no iba a abrazar y agradecer este milagroso favor: el descubrimiento, la captura, quiz\\u00e1 la muerte, de dos agentes del Imperio alem\\u00e1n? Sub\\u00ed a mi cuarto; absurdamente cerr\\u00e9 la puerta con llave y me tir\\u00e9 de espaldas en la estrecha cama de hierro. En la ventana estaban los tejados de siempre y el sol nublado de las seis. Me pareci\\u00f3 incre\\u00edble que ese d\\u00eda sin premoniciones ni s\\u00edmbolos fuera el de mi muerte implacable. A pesar de mi padre muerto, a pesar de haber sido un ni\\u00f1o en un sim\\u00e9trico jard\\u00edn de Hai Feng, \\u00bfyo, ahora, iba a morir? Despu\\u00e9s reflexion\\u00e9 que todas las cosas que suceden a uno precisamente, precisamente ahora. Siglos de siglos y solo en el presente ocurren los hechos; innumerables hombres en el aire, en la tierra y el mar, y todo lo que realmente pasa me pasa a m\\u00ed\\u2026 El casi intolerable recuerdo del rostro acaballado de Madden aboli\\u00f3 esas divagaciones. En mitad de mi odio y de mi terror (ahora no me importa hablar de terror: ahora que he burlado a Richard Madden, ahora que mi garganta anhela la cuerda) pens\\u00e9 que ese guerrero tumultuoso y sin duda feliz no sospechaba que yo pose\\u00eda el Secreto. El nombre del preciso lugar del nuevo parque de artiller\\u00eda brit\\u00e1nico sobre el Ancre. Un p\\u00e1jaro ray\\u00f3 el cielo gris y ciegamente lo traduje en un aeroplano y a ese aeroplano en muchos (en el cielo franc\\u00e9s) aniquilando el parque de artiller\\u00eda con bombas verticales. Si mi boca, antes que la deshiciera un balazo, pudiera gritar ese nombre de modo que lo oyeran en Alemania\\u2026 Mi voz humana era muy pobre. \\u00bfC\\u00f3mo hacerla llegar al o\\u00eddo del jefe? Al o\\u00eddo de aquel hombre enfermo y odioso, que no sab\\u00eda de Runeberg y de m\\u00ed sino que est\\u00e1bamos en Staffordshire y que en vano esperaba noticias nuestras en su \\u00e1rida oficina de Berl\\u00edn, examinando infinitamente peri\\u00f3dicos\\u2026 Dije en voz alta: Debo huir. Me incorpor\\u00e9 sin ruido, en una in\\u00fatil perfecci\\u00f3n de silencio, como si Madden ya estuviera acech\\u00e1ndome. Algo -tal vez la mera ostentaci\\u00f3n de probar que mis recursos eran nulos- me hizo revisar mis bolsillos. Encontr\\u00e9 lo que sab\\u00eda que iba a encontrar. El reloj norteamericano, la cadena de n\\u00edquel y la moneda cuadrangular, el llavero con las comprometedoras llaves in\\u00fatiles del departamento de Runeberg, la libreta, una carta que resolv\\u00ed destruir inmediatamente (y que no destru\\u00ed), el falso pasaporte, una corona, dos chelines y unos peniques, el l\\u00e1piz rojo-azul, el pa\\u00f1uelo, el rev\\u00f3lver con una bala. Absurdamente lo empu\\u00f1\\u00e9 y sopes\\u00e9 para darme valor. Vagamente pens\\u00e9 que un pistoletazo puede o\\u00edrse muy lejos. En diez minutos mi plan estaba maduro. La gu\\u00eda telef\\u00f3nica me dio el nombre de la \\u00fanica persona capaz de transmitir la noticia: viv\\u00eda en un suburbio de Fenton, a menos de media hora de tren. \\u201cSoy un hombre cobarde. Ahora lo digo, ahora que he llevado a t\\u00e9rmino un plan que nadie no calificar\\u00e1 de arriesgado. Yo s\\u00e9 que fue terrible su ejecuci\\u00f3n. No lo hice por Alemania, no. Nada me importa un pa\\u00eds b\\u00e1rbaro, que me ha obligado a la abyecci\\u00f3n de ser un esp\\u00eda. Adem\\u00e1s, yo s\\u00e9 de un hombre de Inglaterra -un hombre modesto- que para m\\u00ed no es menos que Goethe. Arriba de una hora no habl\\u00e9 con \\u00e9l, pero durante una hora fue Goethe\\u2026 Lo hice, porque yo sent\\u00eda que el jefe ten\\u00eda en poco a los de mi raza, a los innumerables antepasados que confluyen en m\\u00ed. Yo quer\\u00eda probarle que un amarillo pod\\u00eda salvar a sus ej\\u00e9rcitos. Adem\\u00e1s, yo deb\\u00eda huir del capit\\u00e1n. Sus manos y su voz pod\\u00edan golpear en cualquier momento a mi puerta. Me vest\\u00ed sin ruido, me dije adi\\u00f3s en el espejo, baj\\u00e9, escudri\\u00f1\\u00e9 la calle tranquila y sal\\u00ed. La estaci\\u00f3n no distaba mucho de casa, pero juzgu\\u00e9 preferible tomar un coche. Arg\\u00fc\\u00ed que as\\u00ed corr\\u00eda menos peligro de ser reconocido; el hecho es que en la calle desierta me sent\\u00eda visible y vulnerable, infinitamente. Recuerdo que le dije al cochero que se detuviera un poco antes de la entrada central. Baj\\u00e9 con lentitud voluntaria y casi penosa; iba a la aldea de Ashgrove, pero saqu\\u00e9 un pasaje para una estaci\\u00f3n m\\u00e1s lejana. El tren sal\\u00eda dentro de muy pocos minutos, a las ocho y cincuenta. Me apresur\\u00e9; el pr\\u00f3ximo saldr\\u00eda a las nueve y media. No hab\\u00eda casi nadie en el and\\u00e9n. Recorr\\u00ed los coches: recuerdo unos labradores, una enlutada, un joven que le\\u00eda con fervor los Anales de T\\u00e1cito, un soldado herido y feliz. Los coches arrancaron al fin. Un hombre que reconoc\\u00ed corri\\u00f3 en vano hasta el l\\u00edmite del and\\u00e9n. Era el capit\\u00e1n Richard Madden. Aniquilado, tr\\u00e9mulo, me encog\\u00ed en la otra punta del sill\\u00f3n, lejos del temido cristal. \\u201cDe esa aniquilaci\\u00f3n pas\\u00e9 a una felicidad casi abyecta. Me dije que ya estaba empe\\u00f1ado mi duelo y que yo hab\\u00eda ganado el primer asalto, al burlar, siquiera por cuarenta minutos, siquiera por un favor del azar, el ataque de mi adversario. Arg\\u00fc\\u00ed que no era m\\u00ednima, ya que sin esa diferencia preciosa que el horario de trenes me deparaba, yo estar\\u00eda en la c\\u00e1rcel o muerto. Arg\\u00fc\\u00ed (no menos sof\\u00edsticamente) que mi felicidad cobarde probaba que yo era hombre capaz de llevar a buen t\\u00e9rmino la aventura. De esa debilidad saqu\\u00e9 fuerzas que no me abandonaron. Preveo que el hombre se resignar\\u00e1 cada d\\u00eda a empresas m\\u00e1s atroces; pronto no habr\\u00e1 sino guerreros y bandoleros; les doy este consejo: El ejecutor de una empresa atroz debe imaginar que ya la ha cumplido, debe imponerse un porvenir que sea irrevocable como el pasado. As\\u00ed proced\\u00ed yo, mientras mis ojos de hombre ya muerto registraban la fluencia de aquel d\\u00eda que era tal vez el \\u00faltimo, y la difusi\\u00f3n de la noche. El tren corr\\u00eda con dulzura, entre fresnos. Se detuvo, casi en medio del campo. Nadie grit\\u00f3 el nombre de la estaci\\u00f3n. \\u00bfAshgrove?, les pregunt\\u00e9 a unos chicos en el and\\u00e9n. Ashgrove, contestaron. Baj\\u00e9. \\u201cUna l\\u00e1mpara ilustraba el and\\u00e9n, pero las caras de los ni\\u00f1os quedaban en la zona de sombra. Uno me interrog\\u00f3: \\u00bfUsted va a casa del doctor Stephen Albert? Sin aguardar contestaci\\u00f3n, otro dijo: La casa queda lejos de aqu\\u00ed, pero usted no se perder\\u00e1 si toma ese camino a la izquierda y en cada encrucijada del camino dobla a la izquierda. Les arroj\\u00e9 una moneda (la \\u00faltima), baj\\u00e9 unos escalones de piedra y entr\\u00e9 en el solitario camino. Este, lentamente, bajaba. Era de tierra elemental, arriba se confund\\u00edan las ramas, la luna baja y circular parec\\u00eda acompa\\u00f1arme. \\u201cPor un instante, pens\\u00e9 que Richard Madden hab\\u00eda penetrado de alg\\u00fan modo mi desesperado prop\\u00f3sito. Muy pronto comprend\\u00ed que eso era imposible. El consejo de siempre doblar a la izquierda me record\\u00f3 que tal era el procedimiento com\\u00fan para descubrir el patio central de ciertos laberintos. Algo entiendo de laberintos: no en vano soy bisnieto de aquel Ts\\u2019ui P\\u00ean, que fue gobernador de Yunnan y que renunci\\u00f3 al poder temporal para escribir una novela que fuera todav\\u00eda m\\u00e1s populosa que el Hung Lu Meng y para edificar un laberinto en el que se perdieran todos los hombres. Trece a\\u00f1os dedic\\u00f3 a esas heterog\\u00e9neas fatigas, pero la mano de un forastero lo asesin\\u00f3 y su novela era insensata y nadie encontr\\u00f3 el laberinto. Bajo \\u00e1rboles ingleses medit\\u00e9 en ese laberinto perdido: lo imagin\\u00e9 inviolado y perfecto en la cumbre secreta de una monta\\u00f1a, lo imagin\\u00e9 borrado por arrozales o debajo del agua, lo imagin\\u00e9 infinito, no ya de quioscos ochavados y de sendas que vuelven, sino de r\\u00edos y provincias y reinos\\u2026 Pens\\u00e9 en un laberinto de laberintos, en un sinuoso laberinto creciente que abarcara el pasado y el porvenir y que implicara de alg\\u00fan modo los astros. Absorto en esas ilusorias im\\u00e1genes, olvid\\u00e9 mi destino de perseguido. Me sent\\u00ed, por un tiempo indeterminado, percibidor abstracto del mundo. El vago y vivo campo, la luna, los restos de la tarde, obraron en m\\u00ed; asimismo el declive que eliminaba cualquier posibilidad de cansancio. La tarde era \\u00edntima, infinita. El camino bajaba y se bifurcaba, entre las ya confusas praderas. Una m\\u00fasica aguda y como sil\\u00e1bica se aproximaba y se alejaba en el vaiv\\u00e9n del viento, empa\\u00f1ada de hojas y de distancia. Pens\\u00e9 que un hombre puede ser enemigo de otros hombres, de otros momentos de otros hombres, pero no de un pa\\u00eds: no de luci\\u00e9rnagas, palabras, jardines, cursos de agua, ponientes. Llegu\\u00e9, as\\u00ed, a un alto port\\u00f3n herrumbrado. Entre las rejas descifr\\u00e9 una alameda y una especie de pabell\\u00f3n. Comprend\\u00ed, de pronto, dos cosas, la primera trivial, la segunda casi incre\\u00edble: la m\\u00fasica ven\\u00eda del pabell\\u00f3n, la m\\u00fasica era china. Por eso, yo la hab\\u00eda aceptado con plenitud, sin prestarle atenci\\u00f3n. No recuerdo si hab\\u00eda una campana o un timbre o si llam\\u00e9 golpeando las manos. El chisporroteo de la m\\u00fasica prosigui\\u00f3. \\u201cPero del fondo de la \\u00edntima casa un farol se acercaba: un farol que rayaban y a ratos anulaban los troncos, un farol de papel, que ten\\u00eda la forma de los tambores y el color de la luna. Lo tra\\u00eda un hombre alto. No vi su rostro, porque me cegaba la luz. Abri\\u00f3 el port\\u00f3n y dijo lentamente en mi idioma. \\u201c-Veo que el piadoso Hsi P\\u2019\\u00eang se empe\\u00f1a en corregir mi soledad. \\u00bfUsted sin duda querr\\u00e1 ver el jard\\u00edn? \\u201cReconoc\\u00ed el nombre de uno de nuestros c\\u00f3nsules y repet\\u00ed desconcertado: \\u201c-\\u00bfEl jard\\u00edn? \\u201c-El jard\\u00edn de senderos que se bifurcan. \\u201cAlgo se agit\\u00f3 en mi recuerdo y pronunci\\u00e9 con incomprensible seguridad: \\u201c-El jard\\u00edn de mi antepasado Ts\\u2019ui P\\u00ean. \\u201c-\\u00bfSu antepasado? \\u00bfSu ilustre antepasado? Adelante. \\u201cEl h\\u00famedo sendero zigzagueaba como los de mi infancia. Llegamos a una biblioteca de libros orientales y occidentales. Reconoc\\u00ed, encuadernados en seda amarilla, algunos tomos manuscritos de la Enciclopedia perdida que dirigi\\u00f3 el tercer emperador de la Dinast\\u00eda Luminosa y que no se dio nunca a la imprenta. El disco del gram\\u00f3fono giraba junto a un f\\u00e9nix de bronce. Recuerdo tambi\\u00e9n un jarr\\u00f3n de la familia rosa y otro, anterior de muchos siglos, de ese color azul que nuestros art\\u00edfices copiaron de los alfareros de Persia\\u2026 \\u201cStephen Albert me observaba, sonriente. Era (ya lo dije) muy alto, de rasgos afilados, de ojos grises y barba gris. Algo de sacerdote hab\\u00eda en \\u00e9l y tambi\\u00e9n de marino; despu\\u00e9s me refiri\\u00f3 que hab\\u00eda sido misionero en Tientsin \\u201cantes de aspirar a sin\\u00f3logo\\u201d. \\u201cNos sentamos; yo en un largo y bajo div\\u00e1n; \\u00e9l de espaldas a la ventana y a un alto reloj circular. Comput\\u00e9 que antes de una hora no llegar\\u00eda mi perseguidor, Richard Madden. Mi determinaci\\u00f3n irrevocable pod\\u00eda esperar. \\u201c-Asombroso destino el de Ts\\u2019ui P\\u00ean -dijo Stephen Albert-. Gobernador de su provincia natal, docto en astronom\\u00eda, en astrolog\\u00eda y en la interpretaci\\u00f3n infatigable de los libros can\\u00f3nicos, ajedrecista, famoso poeta y cal\\u00edgrafo: todo lo abandon\\u00f3 para componer un libro y un laberinto. Renunci\\u00f3 a los placeres de la opresi\\u00f3n, de la justicia, del numeroso lecho, de los banquetes y aun de la erudici\\u00f3n y se enclaustr\\u00f3 durante trece a\\u00f1os en el Pabell\\u00f3n de la L\\u00edmpida Soledad. A su muerte, los herederos no encontraron sino manuscritos ca\\u00f3ticos. La familia, como usted acaso no ignora, quiso adjudicarlos al fuego; pero su albacea -un monje tao\\u00edsta o budista- insisti\\u00f3 en la publicaci\\u00f3n. \\u201c-Los de la sangre de Ts\\u2019ui P\\u00ean -repliqu\\u00e9- seguimos execrando a ese monje. Esa publicaci\\u00f3n fue insensata. El libro es un acervo indeciso de borradores contradictorios. Lo he examinado alguna vez: en el tercer cap\\u00edtulo muere el h\\u00e9roe, en el cuarto est\\u00e1 vivo. En cuanto a la otra empresa de Ts\\u2019ui P\\u00ean, a su Laberinto\\u2026 \\u201c-Aqu\\u00ed est\\u00e1 el Laberinto -dijo indic\\u00e1ndome un alto escritorio laqueado. \\u201c-\\u00a1Un laberinto de marfil! -exclam\\u00e9-. Un laberinto m\\u00ednimo\\u2026 \\u201c-Un laberinto de s\\u00edmbolos -corrigi\\u00f3-. Un invisible laberinto de tiempo. A m\\u00ed, b\\u00e1rbaro ingl\\u00e9s, me ha sido deparado revelar ese misterio di\\u00e1fano. Al cabo de m\\u00e1s de cien a\\u00f1os, los pormenores son irrecuperables, pero no es dif\\u00edcil conjeturar lo que sucedi\\u00f3. Ts\\u2019ui P\\u00ean dir\\u00eda una vez: Me retiro a escribir un libro. Y otra: Me retiro a construir un laberinto. Todos imaginaron dos obras; nadie pens\\u00f3 que libro y laberinto eran un solo objeto. El Pabell\\u00f3n de la L\\u00edmpida Soledad se ergu\\u00eda en el centro de un jard\\u00edn tal vez intrincado; el hecho puede haber sugerido a los hombres un laberinto f\\u00edsico. Ts\\u2019ui P\\u00ean muri\\u00f3; nadie, en las dilatadas tierras que fueron suyas, dio con el laberinto; la confusi\\u00f3n de la novela me sugiri\\u00f3 que ese era el laberinto. Dos circunstancias me dieron la recta soluci\\u00f3n del problema. Una: la curiosa leyenda de que Ts\\u2019ui P\\u00ean se hab\\u00eda propuesto un laberinto que fuera estrictamente infinito: Otra: un fragmento de una carta que descubr\\u00ed. \\u201cAlbert se levant\\u00f3. Me dio, por unos instantes, la espalda; abri\\u00f3 un caj\\u00f3n del \\u00e1ureo y renegrido escritorio. Volvi\\u00f3 con un papel antes carmes\\u00ed; ahora rosado y tenue y cuadriculado. Era justo el renombre caligr\\u00e1fico de Ts\\u2019ui P\\u00ean. Le\\u00ed con incomprensi\\u00f3n y fervor estas palabras que con minucioso pincel redact\\u00f3 un hombre de mi sangre: Dejo a los varios porvenires (no a todos) mi jard\\u00edn de senderos que se bifurcan. Devolv\\u00ed en silencio la hoja. Albert prosigui\\u00f3: \\u201c-Antes de exhumar esta carta, yo me hab\\u00eda preguntado de qu\\u00e9 manera un libro puede ser infinito. No conjetur\\u00e9 otro procedimiento que el de un volumen c\\u00edclico, circular. Un volumen cuya \\u00faltima p\\u00e1gina fuera id\\u00e9ntica a la primera, con posibilidad de continuar indefinidamente. Record\\u00e9 tambi\\u00e9n esa noche que est\\u00e1 en el centro de las 1001 noches, cuando la reina Shahrazad (por una m\\u00e1gica distracci\\u00f3n del copista), se pone a referir textualmente la historia de las 1001 noches, con riesgo de llegar otra vez a la noche en que la refiere, y as\\u00ed hasta lo infinito. Imagin\\u00e9 tambi\\u00e9n una obra plat\\u00f3nica, hereditaria, trasmitida de padre a hijo, en la que cada nuevo individuo agregara un cap\\u00edtulo o corrigiera con piadoso cuidado la p\\u00e1gina de los mayores. Esas conjeturas me distrajeron; pero ninguna parec\\u00eda corresponder, siquiera de un modo remoto, a los contradictorios cap\\u00edtulos de Ts\\u2019ui P\\u00ean. En esa perplejidad, me remitieron de Oxford el manuscrito que usted ha examinado. Me detuve, como es natural, en la frase: Dejo a los varios porvenires (no a todos) mi jard\\u00edn de senderos que se bifurcan. Casi en el acto comprend\\u00ed; el jard\\u00edn de senderos que se bifurcan era la novela ca\\u00f3tica; la frase varios porvenires (no a todos) me sugiri\\u00f3 la imagen de la bifurcaci\\u00f3n en el tiempo, no en el espacio. La relectura general de la obra confirm\\u00f3 esa teor\\u00eda. En todas las ficciones, cada vez que un hombre se enfrenta con diversas alternativas opta por una y elimina las otras; en la del casi inextricable Ts\\u2019ui P\\u00ean, opta -simult\\u00e1neamente- por todas. Crea, as\\u00ed, diversos porvenires, diversos tiempos, que tambi\\u00e9n proliferan y se bifurcan. De ah\\u00ed las contradicciones de la novela. Fang, digamos, tiene un secreto; un desconocido llama a su puerta; Fang resuelve matarlo. Naturalmente, hay varios desenlaces posibles: Fang puede matar al intruso, el intruso puede matar a Fang, ambos pueden salvarse, ambos pueden morir, etc\\u00e9tera. En la obra de Ts\\u2019ui P\\u00ean, todos los desenlaces ocurren; cada uno es el punto de partida de otras bifurcaciones. Alguna vez, los senderos de ese laberinto convergen: por ejemplo, usted llega a esta casa, pero en uno de los pasados posibles usted es mi enemigo, en otro mi amigo. Si se resigna usted a mi pronunciaci\\u00f3n incurable, leeremos unas p\\u00e1ginas. \\u201cSu rostro, en el v\\u00edvido c\\u00edrculo de la l\\u00e1mpara, era sin duda el de un anciano, pero con algo inquebrantable y aun inmortal. Ley\\u00f3 con lenta precisi\\u00f3n dos redacciones de un mismo cap\\u00edtulo \\u00e9pico. En la primera, un ej\\u00e9rcito marcha hacia una batalla a trav\\u00e9s de una monta\\u00f1a desierta; el horror de las piedras y de la sombra le hace menospreciar la vida y logra con facilidad la victoria; en la segunda, el mismo ej\\u00e9rcito atraviesa un palacio en el que hay una fiesta; la resplandeciente batalla les parece una continuaci\\u00f3n de la fiesta y logran la victoria. Yo o\\u00eda con decente veneraci\\u00f3n esas viejas ficciones, acaso menos admirables que el hecho de que las hubiera ideado mi sangre y de que un hombre de un imperio remoto me las restituyera, en el curso de una desesperada aventura, en una isla occidental. \\u201cRecuerdo las palabras finales, repetidas en cada redacci\\u00f3n como un mandamiento secreto: As\\u00ed combatieron los h\\u00e9roes, tranquilo el admirable coraz\\u00f3n, violenta la espada, resignados a matar y a morir. \\u201cDesde ese instante sent\\u00ed a mi alrededor y en mi oscuro cuerpo una invisible, intangible pululaci\\u00f3n. No la pululaci\\u00f3n de los divergentes, paralelos y finalmente coalescentes ej\\u00e9rcitos, sino una agitaci\\u00f3n m\\u00e1s inaccesible, m\\u00e1s \\u00edntima y que ellos de alg\\u00fan modo prefiguraban. Stephen Albert prosigui\\u00f3: \\u201c-No creo que su ilustre antepasado jugara ociosamente a las variaciones. No juzgo veros\\u00edmil que sacrificara trece a\\u00f1os a la infinita ejecuci\\u00f3n de un experimento ret\\u00f3rico. En su pa\\u00eds, la novela es un g\\u00e9nero subalterno; en aquel tiempo era un g\\u00e9nero despreciable. Ts\\u2019ui P\\u00ean fue un novelista genial, pero tambi\\u00e9n fue un hombre de letras que sin duda no se consider\\u00f3 un mero novelista. El testimonio de sus contempor\\u00e1neos proclama -y harto lo confirma su vida- sus aficiones metaf\\u00edsicas, m\\u00edsticas. La controversia filos\\u00f3fica usurpa buena parte de su novela. S\\u00e9 que de todos los problemas, ninguno lo inquiet\\u00f3 y lo trabaj\\u00f3 como el abismal problema del tiempo. Ahora bien, ese es el \\u00fanico problema que no figura en las p\\u00e1ginas del Jard\\u00edn. Ni siquiera usa la palabra que quiere decir tiempo. \\u00bfC\\u00f3mo se explica usted esa voluntaria omisi\\u00f3n? \\u201cPropuse varias soluciones; todas, insuficientes. Las discutimos; al fin, Stephen Albert me dijo: \\u201c-En una adivinanza cuyo tema es el ajedrez, \\u00bfcu\\u00e1l es la \\u00fanica palabra prohibida? \\u201cReflexion\\u00e9 un momento y repuse: \\u201c-La palabra ajedrez. \\u201c-Precisamente -dijo Albert-. El jard\\u00edn de senderos que se bifurcan es una enorme adivinanza, o par\\u00e1bola, cuyo tema es el tiempo; esa causa rec\\u00f3ndita le proh\\u00edbe la menci\\u00f3n de su nombre. Omitir siempre una palabra, recurrir a met\\u00e1foras ineptas y a per\\u00edfrases evidentes, es quiz\\u00e1s el modo m\\u00e1s enf\\u00e1tico de indicarla. Es el modo tortuoso que prefiri\\u00f3, en cada uno de los meandros de su infatigable novela, el oblicuo Ts\\u2019ui P\\u00ean. He confrontado centenares de manuscritos, he corregido los errores que la negligencia de los copistas ha introducido, he conjeturado el plan de ese caos, he restablecido, he cre\\u00eddo restablecer, el orden primordial, he traducido la obra entera: me consta que no emplea una sola vez la palabra tiempo. La explicaci\\u00f3n es obvia: El jard\\u00edn de senderos que se bifurcan es una imagen incompleta, pero no falsa, del universo tal como lo conceb\\u00eda Ts\\u2019ui P\\u00ean. A diferencia de Newton y de Schopenhauer, su antepasado no cre\\u00eda en un tiempo uniforme, absoluto. Cre\\u00eda en infinitas series de tiempos, en una red creciente y vertiginosa de tiempos divergentes, convergentes y paralelos. Esa trama de tiempos que se aproximan, se bifurcan, se cortan o que secularmente se ignoran, abarca todas las posibilidades. No existimos en la mayor\\u00eda de esos tiempos; en algunos existe usted y no yo; en otros, yo, no usted; en otros, los dos. En este, que un favorable azar me depara, usted ha llegado a mi casa; en otro, usted, al atravesar el jard\\u00edn, me ha encontrado muerto; en otro, yo digo estas mismas palabras, pero soy un error, un fantasma. \\u201c-En todos -articul\\u00e9 no sin un temblor- yo agradezco y venero su recreaci\\u00f3n del jard\\u00edn de Ts\\u2019ui P\\u00ean. \\u201c-No en todos -murmur\\u00f3 con una sonrisa-. El tiempo se bifurca perpetuamente hacia innumerables futuros. En uno de ellos soy su enemigo. \\u201cVolv\\u00ed a sentir esa pululaci\\u00f3n de que habl\\u00e9. Me pareci\\u00f3 que el h\\u00famedo jard\\u00edn que rodeaba la casa estaba saturado hasta lo infinito de invisibles personas. Esas personas eran Albert y yo, secretos, atareados y multiformes en otras dimensiones de tiempo. Alc\\u00e9 los ojos y la tenue pesadilla se disip\\u00f3. En el amarillo y negro jard\\u00edn hab\\u00eda un solo hombre; pero ese hombre era fuerte como una estatua, pero ese hombre avanzaba por el sendero y era el capit\\u00e1n Richard Madden. \\u201c-El porvenir ya existe -respond\\u00ed-, pero yo soy su amigo. \\u00bfPuedo examinar de nuevo la carta? \\u201cAlbert se levant\\u00f3. Alto, abri\\u00f3 el caj\\u00f3n del alto escritorio; me dio por un momento la espalda. Yo hab\\u00eda preparado el rev\\u00f3lver. Dispar\\u00e9 con sumo cuidado: Albert se desplom\\u00f3 sin una queja, inmediatamente. Yo juro que su muerte fue instant\\u00e1nea: una fulminaci\\u00f3n. \\u201cLo dem\\u00e1s es irreal, insignificante. Madden irrumpi\\u00f3, me arrest\\u00f3. He sido condenado a la horca. Abominablemente he vencido: he comunicado a Berl\\u00edn el secreto nombre de la ciudad que deben atacar. Ayer la bombardearon; lo le\\u00ed en los mismos peri\\u00f3dicos que propusieron a Inglaterra el enigma de que el sabio sin\\u00f3logo Stephen Albert muriera asesinado por un desconocido, Yu Tsun. El jefe ha descifrado ese enigma. Sabe que mi problema era indicar (a trav\\u00e9s del estr\\u00e9pito de la guerra) la ciudad que se llama Albert y que no hall\\u00e9 otro medio que matar a una persona de ese nombre. No sabe (nadie puede saber) mi innumerable contrici\\u00f3n y cansancio.\\u201d 1. Hip\\u00f3tesis odiosa y estrafalaria. El esp\\u00eda prusiano Hans Rabener alias Viktor Runeberg agredi\\u00f3 con una pistola autom\\u00e1tica al portador de la orden de arresto, capit\\u00e1n Richard Madden. Este, en defensa propia, le caus\\u00f3 heridas que determinaron su muerte. FIN El jard\\u00edn de los senderos que se bifurcan, 1941\",\n          \"El hecho sucedi\\u00f3 en la estancia Los \\u00c1lamos, en el partido de Jun\\u00edn, hacia el sur, en los \\u00faltimos d\\u00edas del mes de marzo de 1928. Su protagonista fue un estudiante de medicina, Baltasar Espinosa. Podemos definirlo por ahora como uno de tantos muchachos porte\\u00f1os, sin otros rasgos dignos de nota que esa facultad oratoria que le hab\\u00eda hecho merecer m\\u00e1s de un premio en el colegio ingl\\u00e9s de Ramos Mej\\u00eda y que una casi ilimitada bondad. No le gustaba discutir; prefer\\u00eda que el interlocutor tuviera raz\\u00f3n y no \\u00e9l. Aunque los azares del juego le interesaban, era un mal jugador, porque le desagradaba ganar. Su abierta inteligencia era perezosa; a los treinta y tres a\\u00f1os le faltaba rendir una materia para graduarse, la que m\\u00e1s lo atra\\u00eda. Su padre, que era librepensador, como todos los se\\u00f1ores de su \\u00e9poca, lo hab\\u00eda instruido en la doctrina de Herbert Spencer, pero su madre, antes de un viaje a Montevideo, le pidi\\u00f3 que todas las noches rezara el Padrenuestro e hiciera la se\\u00f1al de la cruz. A lo largo de los a\\u00f1os no hab\\u00eda quebrado nunca esa promesa. No carec\\u00eda de coraje; una ma\\u00f1ana hab\\u00eda cambiado, con m\\u00e1s indiferencia que ira, dos o tres pu\\u00f1etazos con un grupo de compa\\u00f1eros que quer\\u00edan forzarlo a participar en una huelga universitaria. Abundaba, por esp\\u00edritu de aquiescencia, en opiniones o h\\u00e1bitos discutibles: el pa\\u00eds le importaba menos que el riesgo de que en otras partes creyeran que usamos plumas; veneraba a Francia pero menospreciaba a los franceses; ten\\u00eda en poco a los americanos, pero aprobaba el hecho de que hubiera rascacielos en Buenos Aires; cre\\u00eda que los gauchos de la llanura son mejores jinetes que los de las cuchillas o los cerros. Cuando Daniel, su primo, le propuso veranear en Los \\u00c1lamos, dijo inmediatamente que s\\u00ed, no porque le gustara el campo sino por natural complacencia y porque no busc\\u00f3 razones v\\u00e1lidas para decir que no. El casco de la estancia era grande y un poco abandonado; las dependencias del capataz, que se llamaba Gutre, estaban muy cerca. Los Gutres eran tres: el padre, el hijo, que era singularmente tosco, y una muchacha de incierta paternidad. Eran altos, fuertes, huesudos, de pelo que tiraba a rojizo y de caras aindiadas. Casi no hablaban. La mujer del capataz hab\\u00eda muerto hace a\\u00f1os. Espinosa, en el campo, fue aprendiendo cosas que no sab\\u00eda y que no sospechaba. Por ejemplo, que no hay que galopar cuando uno se est\\u00e1 acercando a las casas y que nadie sale a andar a caballo sino para cumplir con una tarea. Con el tiempo llegar\\u00eda a distinguir los p\\u00e1jaros por el grito. A los pocos d\\u00edas, Daniel tuvo que ausentarse a la capital para cerrar una operaci\\u00f3n de animales. A lo sumo, el negocio le tomar\\u00eda una semana. Espinosa, que ya estaba un poco harto de las bonnes fortunes de su primo y de su infatigable inter\\u00e9s por las variaciones de la sastrer\\u00eda, prefiri\\u00f3 quedarse en la estancia, con sus libros de texto. El calor apretaba y ni siquiera la noche tra\\u00eda un alivio. En el alba, los truenos lo despertaron. El viento zamarreaba las casuarinas. Espinosa oy\\u00f3 las primeras gotas y dio gracias a Dios. El aire fr\\u00edo vino de golpe. Esa tarde, el Salado se desbord\\u00f3. Al otro d\\u00eda, Baltasar Espinosa, mirando desde la galer\\u00eda los campos anegados, pens\\u00f3 que la met\\u00e1fora que equipara la pampa con el mar no era, por lo menos esa ma\\u00f1ana, del todo falsa, aunque Hudson hab\\u00eda dejado escrito que el mar nos parece m\\u00e1s grande, porque lo vemos desde la cubierta del barco y no desde el caballo o desde nuestra altura. La lluvia no cejaba; los Gutres, ayudados o incomodados por el pueblero, salvaron buena parte de la hacienda, aunque hubo muchos animales ahogados. Los caminos para llegar a la estancia eran cuatro: a todos los cubrieron las aguas. Al tercer d\\u00eda, una gotera amenaz\\u00f3 la casa del capataz; Espinosa les dio una habitaci\\u00f3n que quedaba en el fondo, al lado del galp\\u00f3n de las herramientas. La mudanza los fue acercando; com\\u00edan juntos en el gran comedor. El di\\u00e1logo resultaba dif\\u00edcil; los Gutres, que sab\\u00edan tantas cosas en materia de campo, no sab\\u00edan explicarlas. Una noche, Espinosa les pregunt\\u00f3 si la gente guardaba alg\\u00fan recuerdo de los malones, cuando la comandancia estaba en Jun\\u00edn. Le dijeron que s\\u00ed, pero lo mismo hubieran contestado a una pregunta sobre la ejecuci\\u00f3n de Carlos Primero. Espinosa record\\u00f3 que su padre sol\\u00eda decir que casi todos los casos de longevidad que se dan en el campo son casos de mala memoria o de un concepto vago de las fechas. Los gauchos suelen ignorar por igual el a\\u00f1o en que nacieron y el nombre de quien los engendr\\u00f3. En toda la casa no hab\\u00eda otros libros que una serie de la revista La Chacra, un manual de veterinaria, un ejemplar de lujo del Tabar\\u00e9, una Historia del Shorthorn en la Argentina, unos cuantos relatos er\\u00f3ticos o policiales y una novela reciente: Don Segundo Sombra. Espinosa, para distraer de alg\\u00fan modo la sobremesa inevitable, ley\\u00f3 un par de cap\\u00edtulos a los Gutres, que eran analfabetos. Desgraciadamente, el capataz hab\\u00eda sido tropero y no le pod\\u00edan importar las andanzas de otro. Dijo que ese trabajo era liviano, que llevaban siempre un carguero con todo lo que se precisa y que, de no haber sido tropero, no habr\\u00eda llegado nunca hasta la Laguna de G\\u00f3mez, hasta el Bragado y hasta los campos de los N\\u00fa\\u00f1ez, en Chacabuco. En la cocina hab\\u00eda una guitarra; los peones, antes de los hechos que narro, se sentaban en rueda; alguien la templaba y no llegaba nunca a tocar. Esto se llamaba una guitarreada. Espinosa, que se hab\\u00eda dejado crecer la barba, sol\\u00eda demorarse ante el espejo para mirar su cara cambiada y sonre\\u00eda al pensar que en Buenos Aires aburrir\\u00eda a los muchachos con el relato de la inundaci\\u00f3n del Salado. Curiosamente, extra\\u00f1aba lugares a los que no iba nunca y no ir\\u00eda: una esquina de la calle Cabrera en la que hay un buz\\u00f3n, unos leones de mamposter\\u00eda en un port\\u00f3n de la calle Jujuy, a unas cuadras del Once, un almac\\u00e9n con piso de baldosa que no sab\\u00eda muy bien d\\u00f3nde estaba. En cuanto a sus hermanos y a su padre, ya sabr\\u00edan por Daniel que estaba aislado -la palabra, etimol\\u00f3gicamente, era justa- por la creciente. Explorando la casa, siempre cercada por las aguas, dio con una Biblia en ingl\\u00e9s. En las p\\u00e1ginas finales los Guthrie -tal era su nombre genuino- hab\\u00edan dejado escrita su historia. Eran oriundos de Inverness, hab\\u00edan arribado a este continente, sin duda como peones, a principios del siglo diecinueve, y se hab\\u00edan cruzado con indios. La cr\\u00f3nica cesaba hacia mil ochocientos setenta y tantos; ya no sab\\u00edan escribir. Al cabo de unas pocas generaciones hab\\u00edan olvidado el ingl\\u00e9s; el castellano, cuando Espinosa los conoci\\u00f3, les daba trabajo. Carec\\u00edan de fe, pero en su sangre perduraban, como rastros oscuros, el duro fanatismo del calvinista y las supersticiones del pampa. Espinosa les habl\\u00f3 de su hallazgo y casi no escucharon. Hoje\\u00f3 el volumen y sus dedos lo abrieron en el comienzo del Evangelio seg\\u00fan Marcos. Para ejercitarse en la traducci\\u00f3n y acaso para ver si entend\\u00edan algo, decidi\\u00f3 leerles ese texto despu\\u00e9s de la comida. Le sorprendi\\u00f3 que lo escucharan con atenci\\u00f3n y luego con callado inter\\u00e9s. Acaso la presencia de las letras de oro en la tapa le diera m\\u00e1s autoridad. Lo llevan en la sangre, pens\\u00f3. Tambi\\u00e9n se le ocurri\\u00f3 que los hombres, a lo largo del tiempo, han repetido siempre dos historias: la de un bajel perdido que busca por los mares mediterr\\u00e1neos una isla querida, y la de un dios que se hace crucificar en el G\\u00f3lgota. Record\\u00f3 las clases de elocuci\\u00f3n en Ramos Mej\\u00eda y se pon\\u00eda de pie para predicar las par\\u00e1bolas. Los Gutres despachaban la carne asada y las sardinas para no demorar el Evangelio. Una corderita que la muchacha mimaba y adornaba con una cintita celeste se lastim\\u00f3 con un alambrado de p\\u00faa. Para parar la sangre, quer\\u00edan ponerle una telara\\u00f1a; Espinosa la cur\\u00f3 con unas pastillas. La gratitud que esa curaci\\u00f3n despert\\u00f3 no dej\\u00f3 de asombrarlo. Al principio, hab\\u00eda desconfiado de los Gutres y hab\\u00eda escondido en uno de sus libros los doscientos cuarenta pesos que llevaba consigo; ahora, ausente el patr\\u00f3n, \\u00e9l hab\\u00eda tomado su lugar y daba \\u00f3rdenes t\\u00edmidas, que eran inmediatamente acatadas. Los Gutres lo segu\\u00edan por las piezas y por el corredor, como si anduvieran perdidos. Mientras le\\u00eda, not\\u00f3 que le retiraban las migas que \\u00e9l hab\\u00eda dejado sobre la mesa. Una tarde los sorprendi\\u00f3 hablando de \\u00e9l con respeto y pocas palabras. Concluido el Evangelio seg\\u00fan Marcos, quiso leer otro de los tres que faltaban; el padre le pidi\\u00f3 que repitiera el que ya hab\\u00eda le\\u00eddo, para entenderlo bien. Espinosa sinti\\u00f3 que eran como ni\\u00f1os, a quienes la repetici\\u00f3n les agrada m\\u00e1s que la variaci\\u00f3n o la novedad. Una noche so\\u00f1\\u00f3 con el Diluvio, lo cual no es de extra\\u00f1ar; los martillazos de la fabricaci\\u00f3n del arca lo despertaron y pens\\u00f3 que acaso eran truenos. En efecto, la lluvia, que hab\\u00eda amainado, volvi\\u00f3 a recrudecer. El fr\\u00edo era intenso. Le dijeron que el temporal hab\\u00eda roto el techo del galp\\u00f3n de las herramientas y que iban a mostr\\u00e1rselo cuando estuvieran arregladas las vigas. Ya no era un forastero y todos lo trataban con atenci\\u00f3n y casi lo mimaban. A ninguno le gustaba el caf\\u00e9, pero hab\\u00eda siempre un tacita para \\u00e9l, que colmaban de az\\u00facar. El temporal ocurri\\u00f3 un martes. El jueves a la noche lo record\\u00f3 un golpecito suave en la puerta que, por las dudas, \\u00e9l siempre cerraba con llave. Se levant\\u00f3 y abri\\u00f3: era la muchacha. En la oscuridad no la vio, pero por los pasos not\\u00f3 que estaba descalza y despu\\u00e9s, en el lecho, que hab\\u00eda venido desde el fondo, desnuda. No lo abraz\\u00f3, no dijo una sola palabra; se tendi\\u00f3 junto a \\u00e9l y estaba temblando. Era la primera vez que conoc\\u00eda a un hombre. Cuando se fue, no le dio un beso; Espinosa pens\\u00f3 que ni siquiera sab\\u00eda c\\u00f3mo se llamaba. Urgido por una \\u00edntima raz\\u00f3n que no trat\\u00f3 de averiguar, jur\\u00f3 que en Buenos Aires no le contar\\u00eda a nadie esa historia. El d\\u00eda siguiente comenz\\u00f3 como los anteriores, salvo que el padre habl\\u00f3 con Espinosa y le pregunt\\u00f3 si Cristo se dej\\u00f3 matar para salvar a todos los hombres. Espinosa, que era librepensador pero que se vio obligado a justificar lo que les hab\\u00eda le\\u00eddo, le contest\\u00f3: -S\\u00ed. Para salvar a todos del infierno. Gutre le dijo entonces: -\\u00bfQu\\u00e9 es el infierno? -Un lugar bajo tierra donde las \\u00e1nimas arder\\u00e1n y arder\\u00e1n. -\\u00bfY tambi\\u00e9n se salvaron los que le clavaron los clavos? -S\\u00ed -replic\\u00f3 Espinosa, cuya teolog\\u00eda era incierta. Hab\\u00eda temido que el capataz le exigiera cuentas de lo ocurrido anoche con su hija. Despu\\u00e9s del almuerzo, le pidieron que releyera los \\u00faltimos cap\\u00edtulos. Espinosa durmi\\u00f3 una siesta larga, un leve sue\\u00f1o interrumpido por persistentes martillos y por vagas premoniciones. Hacia el atardecer se levant\\u00f3 y sali\\u00f3 al corredor. Dijo como si pensara en voz alta: -Las aguas est\\u00e1n bajas. Ya falta poco. -Ya falta poco -repiti\\u00f3 Gutrel, como un eco. Los tres lo hab\\u00edan seguido. Hincados en el piso de piedra le pidieron la bendici\\u00f3n. Despu\\u00e9s lo maldijeron, lo escupieron y lo empujaron hasta el fondo. La muchacha lloraba. Espinosa entendi\\u00f3 lo que le esperaba del otro lado de la puerta. Cuando la abrieron, vio el firmamento. Un p\\u00e1jaro grit\\u00f3; pens\\u00f3: es un jilguero. El galp\\u00f3n estaba sin techo; hab\\u00edan arrancado las vigas para construir la Cruz. FIN El informe de Brodie, 1970\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"Funes el memorioso\",\n          \"El jard\\u00edn de los senderos que se bifurcan\",\n          \"El evangelio seg\\u00fan Marcos\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metadata\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[Minicuento - Texto completo.]\",\n          \"(1829-1874)\",\n          \"[Cuento - Texto completo.]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Jorge Luis Borges\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Nos quedamos unicamente 30 obras de Borges. Nota: se seleccionaron 30 unicamente por inconvenientes de RAM a la hora de entrenar los modelos\n",
        "\n",
        "df = pd.read_csv('full_corpus.csv').drop(columns=[\"Unnamed: 0\"])\n",
        "df_borges = df[df.author == 'Jorge Luis Borges'][:30]\n",
        "print(f'Cantidad de documentos: {df_borges.shape[0]}')\n",
        "df_borges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "neEB3s3h-1Ph"
      },
      "outputs": [],
      "source": [
        "# Concatenamos todas las obras de Borges y le eliminamos la palabra FIN, ya que la mayoría de las obras la tienen, con el fin de evitar relaciones impropias\n",
        "article_text = ' '.join(df_borges['text'].astype(str))\n",
        "article_text = article_text.replace('FIN', '')\n",
        "\n",
        "# Guardamos el corpus concatenado\n",
        "\n",
        "with open('obras_borges.csv', 'w', encoding='utf-8') as f:\n",
        "    f.write(article_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)\n",
        "\n",
        "# pasar todo el texto a minúscula\n",
        "article_text = article_text.lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwTK6xgLJd8q",
        "outputId": "09fcf1d5-297f-40a9-bbe8-5778a79b8202"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hZIlM52d_Z9g",
        "outputId": "a2a750e3-9898-49b8-acfb-aabcf904d817"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ',\n",
              " '!',\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '¡',\n",
              " '«',\n",
              " '²',\n",
              " '¹',\n",
              " '»',\n",
              " '¿',\n",
              " 'Á',\n",
              " 'É',\n",
              " 'Í',\n",
              " 'Ú',\n",
              " 'á',\n",
              " 'ä',\n",
              " 'é',\n",
              " 'ê',\n",
              " 'ë',\n",
              " 'í',\n",
              " 'ñ',\n",
              " 'ó',\n",
              " 'ö',\n",
              " 'ú',\n",
              " 'ü',\n",
              " '–',\n",
              " '—',\n",
              " '’',\n",
              " '“',\n",
              " '”',\n",
              " '…'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "chars_vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kejTwaM0-_5r"
      },
      "source": [
        "Se observan algunas caracteres que pueden resultar irrelevantes para nuestro caso de estio como: '\\xad' ,'²', '³', '¹'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ijqD-bK__mcg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0010d61c-1bee-4816-c616-6dca3cb579dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68\n"
          ]
        }
      ],
      "source": [
        "# Eliminamos algunos caracteres que no son útiles y redefinimos chars_vocab\n",
        "article_text = article_text.replace('\\xad', '').replace('²', '').replace('³','').replace('¹', '')\n",
        "chars_vocab = set(article_text)\n",
        "print(len(chars_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "\n",
        "# Nota el diccionario char2idx se extrajo de una corrida previa y es necesario definirlo de manera hard-codeada para utilizar los modelos guardados\n",
        "char2idx = {'e': 0,\n",
        " '8': 1,\n",
        " '5': 2,\n",
        " 'c': 3,\n",
        " 't': 4,\n",
        " 'n': 5,\n",
        " '¿': 6,\n",
        " '¡': 7,\n",
        " 'l': 8,\n",
        " '—': 9,\n",
        " 'j': 10,\n",
        " ':': 11,\n",
        " 'f': 12,\n",
        " 'x': 13,\n",
        " 'z': 14,\n",
        " 'y': 15,\n",
        " 'u': 16,\n",
        " 'q': 17,\n",
        " '”': 18,\n",
        " '…': 19,\n",
        " 'á': 20,\n",
        " 'a': 21,\n",
        " 'g': 22,\n",
        " '-': 23,\n",
        " 'o': 24,\n",
        " ';': 25,\n",
        " '7': 26,\n",
        " '*': 27,\n",
        " '2': 28,\n",
        " 'w': 29,\n",
        " '!': 30,\n",
        " 'é': 31,\n",
        " 'í': 32,\n",
        " 'ú': 33,\n",
        " '(': 34,\n",
        " '4': 35,\n",
        " 'ü': 36,\n",
        " '?': 37,\n",
        " '6': 38,\n",
        " '’': 39,\n",
        " ' ': 40,\n",
        " 'ö': 41,\n",
        " 'm': 42,\n",
        " 'ê': 43,\n",
        " 'b': 44,\n",
        " 'i': 45,\n",
        " 'ñ': 46,\n",
        " 'v': 47,\n",
        " 'k': 48,\n",
        " 'r': 49,\n",
        " '.': 50,\n",
        " '1': 51,\n",
        " 'p': 52,\n",
        " ')': 53,\n",
        " '3': 54,\n",
        " '9': 55,\n",
        " '0': 56,\n",
        " '«': 57,\n",
        " '–': 58,\n",
        " '»': 59,\n",
        " 'ë': 60,\n",
        " 'h': 61,\n",
        " 's': 62,\n",
        " 'ó': 63,\n",
        " ',': 64,\n",
        " 'ä': 65,\n",
        " 'd': 66,\n",
        " '“': 67}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WSSmg9jtKP0T"
      },
      "outputs": [],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NmxQdxl8LRCg"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcKRl70HFTzG",
        "outputId": "72cfb855-f8cd-4cd1-9c65-19adb881560e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([21, 44,  0,  8, 40, 15, 40,  3, 21, 32,  5, 40, 62,  0, 40,  0,  5,\n",
              "        3, 24,  5,  4, 49, 21, 49, 24,  5, 40, 66,  0, 62, 52, 16, 31, 62,\n",
              "       40, 66,  0, 40,  8, 21, 40, 42, 16,  0, 49,  4,  0, 40, 66,  0, 40,\n",
              "       21, 44,  0,  8, 50, 40,  3, 21, 42, 45,  5, 21, 44, 21,  5, 40, 52,\n",
              "       24, 49, 40,  0,  8, 40, 66,  0, 62, 45,  0, 49,  4, 24, 40, 15, 40,\n",
              "       62,  0, 40, 49,  0,  3, 24,  5, 24,  3, 45,  0, 49, 24,  5])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVpLCKSZFXZO",
        "outputId": "77a9ec1a-e29d-4167-d27d-89f2a10a35a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([44,  0,  8, 40, 15, 40,  3, 21, 32,  5, 40, 62,  0, 40,  0,  5,  3,\n",
              "       24,  5,  4, 49, 21, 49, 24,  5, 40, 66,  0, 62, 52, 16, 31, 62, 40,\n",
              "       66,  0, 40,  8, 21, 40, 42, 16,  0, 49,  4,  0, 40, 66,  0, 40, 21,\n",
              "       44,  0,  8, 50, 40,  3, 21, 42, 45,  5, 21, 44, 21,  5, 40, 52, 24,\n",
              "       49, 40,  0,  8, 40, 66,  0, 62, 45,  0, 49,  4, 24, 40, 15, 40, 62,\n",
              "        0, 40, 49,  0,  3, 24,  5, 24,  3, 45,  0, 49, 24,  5, 40])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "# Definiendo los modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rkMCZvmhrQz4"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
        "\n",
        "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zUHX3r5JD-MG"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl,patience=5, name_model=\"my_model.keras\"):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.history_ppl = history_ppl\n",
        "      self.patience = patience\n",
        "      self.name_model = name_model\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        print(self.name_model)\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        self.history_ppl.append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          self.model.save(self.name_model)\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M1QjcjE-_5u"
      },
      "source": [
        "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas `CategoryEncoding` que transforma a índices a vectores OHE y `TimeDistributed` que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "Zd2OkfQYs2Q7",
        "outputId": "eda6ce1a-d490-4075-c02a-253ed789f551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │        \u001b[38;5;34m53,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)       │        \u001b[38;5;34m13,668\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,668</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,468\u001b[0m (263.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,468</span> (263.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,468\u001b[0m (263.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,468</span> (263.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Definimos para todos los modelos el vocab_size como la cantidad de caracteres permitidos\n",
        "\n",
        "vocab_size = len(chars_vocab)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oQq1PHDkxDvN",
        "outputId": "7cfdfc21-3837-4f93-ff7d-b3a65db928aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5425srnn.keras\n",
            "\n",
            " mean perplexity: 8.269874717443043 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 40ms/step - loss: 2.5423\n",
            "Epoch 2/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0750srnn.keras\n",
            "\n",
            " mean perplexity: 7.378323554992676 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - loss: 2.0749\n",
            "Epoch 3/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9580srnn.keras\n",
            "\n",
            " mean perplexity: 6.933388296884435 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 26ms/step - loss: 1.9579\n",
            "Epoch 4/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8954srnn.keras\n",
            "\n",
            " mean perplexity: 6.865189506352403 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.8954\n",
            "Epoch 5/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8576srnn.keras\n",
            "\n",
            " mean perplexity: 6.642576873757457 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 1.8576\n",
            "Epoch 6/20\n",
            "\u001b[1m924/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8324srnn.keras\n",
            "\n",
            " mean perplexity: 6.515368888396343 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - loss: 1.8324\n",
            "Epoch 7/20\n",
            "\u001b[1m922/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8143srnn.keras\n",
            "\n",
            " mean perplexity: 6.512457986824385 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 26ms/step - loss: 1.8143\n",
            "Epoch 8/20\n",
            "\u001b[1m924/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8007srnn.keras\n",
            "\n",
            " mean perplexity: 6.450381841368348 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 20ms/step - loss: 1.8007\n",
            "Epoch 9/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7882srnn.keras\n",
            "\n",
            " mean perplexity: 6.474379559964624 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.7882\n",
            "Epoch 10/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7803srnn.keras\n",
            "\n",
            " mean perplexity: 6.340836885776229 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.7803\n",
            "Epoch 11/20\n",
            "\u001b[1m924/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7730srnn.keras\n",
            "\n",
            " mean perplexity: 6.302483777508481 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 1.7730\n",
            "Epoch 12/20\n",
            "\u001b[1m923/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7649srnn.keras\n",
            "\n",
            " mean perplexity: 6.327579771744386 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - loss: 1.7649\n",
            "Epoch 13/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7599srnn.keras\n",
            "\n",
            " mean perplexity: 6.274072109287932 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.7599\n",
            "Epoch 14/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7556srnn.keras\n",
            "\n",
            " mean perplexity: 6.358556576357543 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 1.7556\n",
            "Epoch 15/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7500srnn.keras\n",
            "\n",
            " mean perplexity: 6.293218727330215 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.7500\n",
            "Epoch 16/20\n",
            "\u001b[1m924/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7474srnn.keras\n",
            "\n",
            " mean perplexity: 6.283082726802535 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.7474\n",
            "Epoch 17/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7426srnn.keras\n",
            "\n",
            " mean perplexity: 6.291513538542595 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.7426\n",
            "Epoch 18/20\n",
            "\u001b[1m922/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7396srnn.keras\n",
            "\n",
            " mean perplexity: 6.215693503845739 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - loss: 1.7396\n",
            "Epoch 19/20\n",
            "\u001b[1m924/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7367srnn.keras\n",
            "\n",
            " mean perplexity: 6.233448856204521 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 1.7367\n",
            "Epoch 20/20\n",
            "\u001b[1m923/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7346srnn.keras\n",
            "\n",
            " mean perplexity: 6.145303616541942 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 1.7346\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl,5, name_model=\"srnn.keras\")], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K30JHB3Dv-mx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVdbB_gI-_5v"
      },
      "source": [
        "Resultados:\n",
        "- Épocas: 20\n",
        "- Perplexity final media: 6.14\n",
        "\n",
        "_Nota: el siguiente gráfico se obtuvo de un entrenamiento previo del modelo que no se muestra en los logs por falta de recursos de GPU de colab_\n",
        "\n",
        "\n",
        "Se observa una mejora en el modelo a medida que aumentan las épocas. En la época 5 se observa un cambio de desaceleración de mejora en la \"Perplexity\", y se alcanza un valor asíntotico de 6 en las épocas finales.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Rhy5hZN38qfO"
      },
      "outputs": [],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model_srnn = keras.models.load_model('srnn.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzx0wH0M-_5v"
      },
      "source": [
        "## GRU\n",
        "\n",
        "Este modelo se presenta como una evolución del modelo básico recurrente (SRNN) para el problema de \"Long Short Term Memory\", pero sin la misma perfomance que las redes LSTM, aunque sí, más sencillas y baratas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "collapsed": true,
        "id": "cDhdcSb5WxM2",
        "outputId": "d38258ed-a1db-4efe-bc0a-aba7f556016b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │       \u001b[38;5;34m162,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)       │        \u001b[38;5;34m13,668\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">162,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,668</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m175,668\u001b[0m (686.20 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,668</span> (686.20 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m175,668\u001b[0m (686.20 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,668</span> (686.20 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from keras.layers import GRU\n",
        "\n",
        "model_gru = Sequential()\n",
        "\n",
        "model_gru.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model_gru.add(GRU(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model_gru.add(Dense(vocab_size, activation='softmax'))\n",
        "model_gru.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model_gru.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOtqXXHEYIuK",
        "outputId": "21bda966-efff-49ee-d461-3bfa1a9aa8e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 2.6177gru.keras\n",
            "\n",
            " mean perplexity: 8.599032279644304 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 354ms/step - loss: 2.6175\n",
            "Epoch 2/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 2.0566gru.keras\n",
            "\n",
            " mean perplexity: 7.501024678918242 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 354ms/step - loss: 2.0566\n",
            "Epoch 3/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.8958gru.keras\n",
            "\n",
            " mean perplexity: 6.87974998832659 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 352ms/step - loss: 1.8958\n",
            "Epoch 4/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.7816gru.keras\n",
            "\n",
            " mean perplexity: 6.499714834999492 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 335ms/step - loss: 1.7815\n",
            "Epoch 5/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.7027gru.keras\n",
            "\n",
            " mean perplexity: 6.37394799894959 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 334ms/step - loss: 1.7027\n",
            "Epoch 6/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.6465gru.keras\n",
            "\n",
            " mean perplexity: 6.198693280001633 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 333ms/step - loss: 1.6464\n",
            "Epoch 7/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 1.6044gru.keras\n",
            "\n",
            " mean perplexity: 6.117613453901451 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 335ms/step - loss: 1.6044\n",
            "Epoch 8/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.5720gru.keras\n",
            "\n",
            " mean perplexity: 6.183587798635468 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 333ms/step - loss: 1.5720\n",
            "Epoch 9/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.5459gru.keras\n",
            "\n",
            " mean perplexity: 6.066774421065818 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 349ms/step - loss: 1.5459\n",
            "Epoch 10/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 1.5246gru.keras\n",
            "\n",
            " mean perplexity: 6.0079903452451 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 350ms/step - loss: 1.5246\n",
            "Epoch 11/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 1.5059gru.keras\n",
            "\n",
            " mean perplexity: 6.019995794496463 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 342ms/step - loss: 1.5059\n",
            "Epoch 12/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 1.4918gru.keras\n",
            "\n",
            " mean perplexity: 5.975856031625326 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 332ms/step - loss: 1.4918\n",
            "Epoch 13/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 1.4784gru.keras\n",
            "\n",
            " mean perplexity: 6.01545962714057 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 330ms/step - loss: 1.4784\n",
            "Epoch 14/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.4672gru.keras\n",
            "\n",
            " mean perplexity: 5.9532086958412 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 330ms/step - loss: 1.4671\n",
            "Epoch 15/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 1.4571gru.keras\n",
            "\n",
            " mean perplexity: 5.956815078058316 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 331ms/step - loss: 1.4571\n",
            "Epoch 16/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.4479gru.keras\n",
            "\n",
            " mean perplexity: 5.938820927197696 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 349ms/step - loss: 1.4479\n",
            "Epoch 17/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 1.4399gru.keras\n",
            "\n",
            " mean perplexity: 6.013728716446243 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 331ms/step - loss: 1.4399\n",
            "Epoch 18/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.4335gru.keras\n",
            "\n",
            " mean perplexity: 5.949623551077515 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 350ms/step - loss: 1.4335\n",
            "Epoch 19/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.4266gru.keras\n",
            "\n",
            " mean perplexity: 6.000128871611967 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 335ms/step - loss: 1.4266\n",
            "Epoch 20/20\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.4207gru.keras\n",
            "\n",
            " mean perplexity: 5.995490247966679 \n",
            "\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 333ms/step - loss: 1.4207\n"
          ]
        }
      ],
      "source": [
        "history_ppl = []\n",
        "hist = model_gru.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl,5, name_model=\"gru.keras\")], batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL8bZ5B4-_5v"
      },
      "source": [
        "Resultados:\n",
        "- Épocas: 20\n",
        "- Perplexity final media: 5.99\n",
        "\n",
        "_Nota: el siguiente gráfico se obtuvo de un entrenamiento previo del modelo que no se muestra en los logs por falta de recursos de GPU de colab_\n",
        "\n",
        "\n",
        "Al igual que en el SRNN, se observa una mejora en el modelo a medida que aumentan las épocas. En la época 5 se observa un cambio de desaceleración de mejora en la \"Perplexity\", y se alcanza un valor asíntotico de 6 en las épocas finales.\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "LNoItskP-_5w"
      },
      "outputs": [],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model_gru = keras.models.load_model('gru.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0iym27e-_5w"
      },
      "source": [
        "## LSTM (Long Short Term Memory)\n",
        "\n",
        "Este modelo presenta una solución forma al problema de \"gradiente evanescente\" propia de las RNN, en el cual se incorpora un estado de memoria de largo plazo y celdas que ponderan los términos más relevantes por medio de una entrada y salida propia de un catálogo de términos (C)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "-sIlkYWKXU_w",
        "outputId": "926e7e2a-6eba-4293-991f-55c51df754a3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │       \u001b[38;5;34m215,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)       │        \u001b[38;5;34m13,668\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">215,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,668</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m228,868\u001b[0m (894.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">228,868</span> (894.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m228,868\u001b[0m (894.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">228,868</span> (894.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from keras.layers import LSTM\n",
        "\n",
        "model_lstm = Sequential()\n",
        "\n",
        "model_lstm.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model_lstm.add(LSTM(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model_lstm.add(Dense(vocab_size, activation='softmax'))\n",
        "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model_lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hIVwR-qX-Uy"
      },
      "outputs": [],
      "source": [
        "history_ppl = []\n",
        "hist = model_lstm.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl,5, name_model=\"lstm.keras\")], batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxSd6-E5-_5w"
      },
      "source": [
        "Resultados:\n",
        "- Épocas: 20\n",
        "- Perplexity final media: 5.55\n",
        "\n",
        "_Nota: el siguiente gráfico se obtuvo de un entrenamiento previo del modelo que no se muestra en los logs por falta de recursos de GPU de colab_\n",
        "\n",
        "\n",
        "Al igual que en el SRNN, se observa una mejora en el modelo a medida que aumentan las épocas. En la época 5 se observa un cambio de desaceleración de mejora en la \"Perplexity\", y se alcanza un valor mínimo de 5.55. Sin embargo, no se oberva un comportamiendo asintótico como en los casos previos\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBCm0_bA-_5w"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "XnNi0Vdq-_5w"
      },
      "outputs": [],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model_lstm = keras.models.load_model('lstm.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL7Alrgg-_5w"
      },
      "source": [
        "## SRNN con optimizador \"Adam\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "Iz10tggk-_5w",
        "outputId": "a06822f9-6dec-457c-8638-93c2548bbab9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │        \u001b[38;5;34m53,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)       │        \u001b[38;5;34m13,668\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,668</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,468\u001b[0m (263.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,468</span> (263.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,468\u001b[0m (263.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,468</span> (263.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "vocab_size = len(chars_vocab)\n",
        "\n",
        "model_adam = Sequential()\n",
        "\n",
        "model_adam.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model_adam.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model_adam.add(Dense(vocab_size, activation='softmax'))\n",
        "model_adam.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model_adam.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KB24Bpt-_5w"
      },
      "outputs": [],
      "source": [
        "history_ppl = []\n",
        "hist = model_adam.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl,5, name_model=\"srnn_adam.keras\")], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OOdU5iW-_5x"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21QoRVmO-_5x"
      },
      "source": [
        "Resultados:\n",
        "- Épocas: 20\n",
        "- Perplexity final media: 5.44\n",
        "\n",
        "_Nota: el siguiente gráfico se obtuvo de un entrenamiento previo del modelo que no se muestra en los logs por falta de recursos de GPU de colab_\n",
        "\n",
        "\n",
        "Al igual que en el SRNN, se observa una mejora en el modelo a medida que aumentan las épocas. En la época 5 se observa un cambio de desaceleración de mejora en la \"Perplexity\", y se alcanza un valor mínimo de 5.44. Sin embargo, al igual que en el caso de LSTM, no se observa un comportamiendo asintótico claro, indicando que es posible seguir mejoradndo el aprendizaje.\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model_adam = keras.models.load_model('srnn_adam.keras')"
      ],
      "metadata": {
        "id": "UTdCr9KNAgVP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "# Predicción del próximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBvKHFPmzpy2",
        "outputId": "4ee1e6e8-2844-4d11-b83d-d5963041f55a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting typing_extensions==4.7.1\n",
            "  Using cached typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: typing_extensions\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastapi 0.115.12 requires typing-extensions>=4.8.0, but you have typing-extensions 4.7.1 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires typing-extensions>=4.10.0, but you have typing-extensions 4.7.1 which is incompatible.\n",
            "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.7.1 which is incompatible.\n",
            "pydantic 2.11.3 requires typing-extensions>=4.12.2, but you have typing-extensions 4.7.1 which is incompatible.\n",
            "typeguard 4.4.2 requires typing_extensions>=4.10.0, but you have typing-extensions 4.7.1 which is incompatible.\n",
            "google-genai 1.10.0 requires typing-extensions<5.0.0,>=4.11.0, but you have typing-extensions 4.7.1 which is incompatible.\n",
            "openai 1.75.0 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.7.1 which is incompatible.\n",
            "typing-inspection 0.4.0 requires typing-extensions>=4.12.0, but you have typing-extensions 4.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing_extensions-4.7.1\n"
          ]
        }
      ],
      "source": [
        "# Se puede usar gradio para probar el modelo\n",
        "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
        "# https://gradio.app/\n",
        "\n",
        "!pip install -q gradio\n",
        "!pip install typing_extensions==4.7.1 --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "HNyBykvhzs7-",
        "outputId": "0bc73655-4283-49bc-d26b-dfdebea4c77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://a8c0091320e33bb66b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a8c0091320e33bb66b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://a8c0091320e33bb66b.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "model = model_srnn # model_gru model_lstm\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "# Generación de secuencias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE_prnkJ-_5x"
      },
      "source": [
        "## Greedy search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoFqRC5pxzqS",
        "outputId": "4ff4d2bf-51cb-4985-dd6a-d11df18c6a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "Input text: \"bioy comtemplaba a un perro salir por la puerta de vidrio\"\n",
            "========================================\n",
            "Model: srnn.keras\n",
            "Output text: bioy comtemplaba a un perro salir por la puerta de vidrios en la casa de la casa de la casa de la\n",
            "========================================\n",
            "Model: lstm.keras\n",
            "Output text: bioy comtemplaba a un perro salir por la puerta de vidrio de la cara de la cara de la cara de la \n",
            "========================================\n",
            "Model: gru.keras\n",
            "Output text: bioy comtemplaba a un perro salir por la puerta de vidrio de la cara de la cara de la cara de la \n",
            "========================================\n",
            "Model: srnn_adam.keras\n",
            "Output text: bioy comtemplaba a un perro salir por la puerta de vidrio de la calle a la primera de la calle a \n"
          ]
        }
      ],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "\n",
        "input_text='bioy comtemplaba a un perro salir por la puerta de vidrio'\n",
        "print('='*40)\n",
        "print(f'Input text: \\\"{input_text}\\\"')\n",
        "model_names = ['srnn.keras','lstm.keras','gru.keras','srnn_adam.keras']\n",
        "for model_name in model_names:\n",
        "    print('=' * 40)\n",
        "    print(f'Model: {model_name}')\n",
        "    model = keras.models.load_model(model_name)\n",
        "    output_text = generate_seq(model, input_text, max_length=max_context_size, n_words=40)\n",
        "    print(f'Output text: {output_text}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXAIoNbO-_5y"
      },
      "source": [
        "La generación de texto por medio del modelo \"Greedy Search\", encuentra el siguiente caracter más probable para la secuencia de entrada. Esto genera, junto con la falta muestreo aleatorio con temperatura, la generación de loops repetitivos, tal como pueden observarse en los ejemplos anteriores.\n",
        "\n",
        "A su vez, se observa como los modelos GRU y LSTM tienen un comporamiento similar, ya que en ambos casos se utilizan estrategías para reducir el problema del gradiente evanescente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeLqAoOYW1Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4a3ead3-53f9-40ca-cb3e-73d774002eab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "Input text: \"bioy comtemplaba\"\n",
            "========================================\n",
            "Model: srnn.keras\n",
            "Temp: 1\n",
            "Mode: det\n",
            "Output 1: bioy comtemplaba en un solo que el hombre de l\n",
            "Output 2: bioy comtemplaba en un solo que el hombre de u\n",
            "Output 3: bioy comtemplaba en un solo que el hombre. el \n",
            "Output 4: bioy comtemplaba en un solo que el hombre del \n",
            "Output 5: bioy comtemplaba en un solo que el hombre de a\n",
            "========================================\n",
            "Model: srnn.keras\n",
            "Temp: 1\n",
            "Mode: sto\n",
            "Output 1: bioy comtemplaban el nombre sobre los perdido \n",
            "Output 2: bioy comtemplaban el nombre sobre los perdidad\n",
            "Output 3: bioy comtemplaban el nombre sobre los perdidas\n",
            "Output 4: bioy comtemplaban el nombre sobre los perdidar\n",
            "Output 5: bioy comtemplaban el nombre sobre los perdidas\n",
            "========================================\n",
            "Model: srnn.keras\n",
            "Temp: 10\n",
            "Mode: det\n",
            "Output 1: bioy comtemplaba en un solo que el hombre de l\n",
            "Output 2: bioy comtemplaba en un solo que el hombre de u\n",
            "Output 3: bioy comtemplaba en un solo que el hombre. el \n",
            "Output 4: bioy comtemplaba en un solo que el hombre del \n",
            "Output 5: bioy comtemplaba en un solo que el hombre de a\n",
            "========================================\n",
            "Model: srnn.keras\n",
            "Temp: 10\n",
            "Mode: sto\n",
            "Output 1: bioy comtemplaba5--plsrgo–poe4a?“hí ficúnq)).8\n",
            "Output 2: bioy comtemplaba5--plsrgo–poe4a?“hí ficúw ê7”g\n",
            "Output 3: bioy comtemplaba5--plsrgo–poe4a?“hí ficúnq)).i\n",
            "Output 4: bioy comtemplaba5--plsrgo–poe4a?“hí ficúnq)).3\n",
            "Output 5: bioy comtemplaba5--plsrgo–poe4a?“hí ficúnq)).f\n",
            "========================================\n",
            "Model: srnn.keras\n",
            "Temp: 100\n",
            "Mode: det\n",
            "Output 1: bioy comtemplaba en un solo que el hombre de l\n",
            "Output 2: bioy comtemplaba en un solo que el hombre de u\n",
            "Output 3: bioy comtemplaba en un solo que el hombre. el \n",
            "Output 4: bioy comtemplaba en un solo que el hombre del \n",
            "Output 5: bioy comtemplaba en un solo que el hombre de a\n",
            "========================================\n",
            "Model: srnn.keras\n",
            "Temp: 100\n",
            "Mode: sto\n",
            "Output 1: bioy comtemplabaü6»—yg¿aba1ó?…(» pa!oüööu5séëk\n",
            "Output 2: bioy comtemplabaü6»—yg¿aba1ó?…(» pa!oüööu5séë«\n",
            "Output 3: bioy comtemplabaü6»—yg¿aba1ó?…(» pa!oüööu5séë:\n",
            "Output 4: bioy comtemplabaü6»—yg¿aba1ó?…(» pa!oüöbk?b?“ö\n",
            "Output 5: bioy comtemplabaü6»—yg¿aba1ó?…(» pa!oüööuewäq¿\n",
            "========================================\n",
            "Model: lstm.keras\n",
            "Temp: 1\n",
            "Mode: det\n",
            "Output 1: bioy comtemplaba en la casa de los hombres de \n",
            "Output 2: bioy comtemplaba en la casa de los hombres que\n",
            "Output 3: bioy comtemplaba en la casa de los hombres del\n",
            "Output 4: bioy comtemplaba en la casa de los hombres, la\n",
            "Output 5: bioy comtemplaba en la casa de los hombres, pe\n",
            "========================================\n",
            "Model: lstm.keras\n",
            "Temp: 1\n",
            "Mode: sto\n",
            "Output 1: bioy comtemplaba en la mena de la capataba en \n",
            "Output 2: bioy comtemplaba en la mena de la capataba y r\n",
            "Output 3: bioy comtemplaba en la mena de la capataba y c\n",
            "Output 4: bioy comtemplaba en la mena de la capataba en \n",
            "Output 5: bioy comtemplaba en la mena de la capataba en \n",
            "========================================\n",
            "Model: lstm.keras\n",
            "Temp: 10\n",
            "Mode: det\n",
            "Output 1: bioy comtemplaba en la casa de los hombres de \n",
            "Output 2: bioy comtemplaba en la casa de los hombres que\n",
            "Output 3: bioy comtemplaba en la casa de los hombres del\n",
            "Output 4: bioy comtemplaba en la casa de los hombres, la\n",
            "Output 5: bioy comtemplaba en la casa de los hombres, pe\n",
            "========================================\n",
            "Model: lstm.keras\n",
            "Temp: 10\n",
            "Mode: sto\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "input_text='bioy comtemplaba'\n",
        "print('='*40)\n",
        "print(f'Input text: \\\"{input_text}\\\"')\n",
        "model_names = ['srnn.keras','lstm.keras','gru.keras','srnn_adam.keras']\n",
        "temp_values = [1,10,100]\n",
        "modes = ['det','sto']\n",
        "for model_name in model_names:\n",
        "    for temp in temp_values:\n",
        "        for mode in modes:\n",
        "            print('=' * 40)\n",
        "            print(f'Model: {model_name}')\n",
        "            print(f'Temp: {temp}')\n",
        "            print(f'Mode: {mode}')\n",
        "            model = keras.models.load_model(model_name)\n",
        "            salidas = beam_search(model,num_beams=5,num_words=30,input=input_text,temp=temp,mode=mode)\n",
        "            # veamos las salidas mas probables\n",
        "            for idx,salida in enumerate(salidas):\n",
        "                print(f'Output {idx+1}: {decode(salida)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dx-A0Ro-_5y"
      },
      "source": [
        "# Conclusiones\n",
        "\n",
        "Al comparar los resultados de los distintos modelos utilizando el método de predicción con \"Beam Search\", podemos extraer las siguientes conclusiones:\n",
        "- Al comparar los modelos por separado, de manera deterministica, el modelo LSTM genera texto más coherente, gramatical y fluido. Lo que demuestra que la SRNN tiene menor capacidad para modelar dependencias largas que la LSTM\n",
        "- Al incluir la temperatura en la predicción de resultados,ambos modelos estan infiriendo caracteres extremadamente improbables, lo que demuestra la gran dependencia que existe con la temperatura. Esto indica que las distribuciones de probabilidad deterministicas no se encuentra muy desbalanceadas entre sí, haciendolos muy sensibles a cualquier \"ruido\" estocástico.\n",
        "- Si comparamos la complejidad de los modelos, la cantidad de parámetros entrenables, obseramos que la más sencilla es la SRNN con 70000 parametros aproximadamente, la GRU con 180000 parámetros aproximadamente (x2.6) y la LSTM con 225000 parámetros aproximadamente (x3.25), lo cual se relaciona con el resultado final, obteniendo frases más comprensibles con los últimos dos modelos en comparación con la primera. Sin embargo, los niveles de \"perplexity\" en todos los casos alcanzan valores similares, lo cual nos da a entender que analizar una red únicamente por medio de este parámetro es incompleto.\n",
        "- Al utilizar el mismo modelo de SRNN pero con optimizador ADAM se observa una disminución de la perplexity final en comparación con el mismo modelo utilizando el optimizador rmsprop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_LlqmtEW1Hn"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}